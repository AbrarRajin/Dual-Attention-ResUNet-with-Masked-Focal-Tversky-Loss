{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f220060",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "class ChangeDetectionFloodPreprocessor:\n",
    "    def __init__(self, base_path, output_path, img_size=256, test_size=0.15, val_size=0.15, random_state=42):\n",
    "        \"\"\"\n",
    "        Preprocessor for change detection flood dataset\n",
    "        \n",
    "        Args:\n",
    "            base_path: Path to dataset containing A, B, Label folders\n",
    "            output_path: Path to save preprocessed data\n",
    "            img_size: Target image size (should be 256 since input is already 256x256)\n",
    "            test_size: Fraction of data for test set\n",
    "            val_size: Fraction of remaining data for validation set\n",
    "            random_state: Random seed for reproducible splits\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "        self.output_path = output_path\n",
    "        self.img_size = img_size\n",
    "        self.test_size = test_size\n",
    "        self.val_size = val_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        # Define folder paths\n",
    "        self.pre_flood_dir = os.path.join(base_path, 'A')  # Pre-flood images\n",
    "        self.post_flood_dir = os.path.join(base_path, 'B')  # Post-flood images\n",
    "        self.label_dir = os.path.join(base_path, 'Label')  # Ground truth masks\n",
    "        \n",
    "        # Statistics dictionary to track dataset properties\n",
    "        self.stats = {\n",
    "            'train': {'count': 0, 'flood_pixels': 0, 'total_pixels': 0},\n",
    "            'val': {'count': 0, 'flood_pixels': 0, 'total_pixels': 0},\n",
    "            'test': {'count': 0, 'flood_pixels': 0, 'total_pixels': 0}\n",
    "        }\n",
    "        \n",
    "        self.create_output_dirs()\n",
    "        \n",
    "    def create_output_dirs(self):\n",
    "        \"\"\"Create output directory structure\"\"\"\n",
    "        if os.path.exists(self.output_path):\n",
    "            shutil.rmtree(self.output_path)\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'pre_flood'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'post_flood'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'masks'), exist_ok=True)\n",
    "            \n",
    "        # Create splits directory\n",
    "        os.makedirs(os.path.join(self.output_path, 'splits'), exist_ok=True)\n",
    "            \n",
    "        print(f\"Created output directories at {self.output_path}\")\n",
    "    \n",
    "    def get_image_list(self):\n",
    "        \"\"\"Get list of all image names and verify they exist in all folders\"\"\"\n",
    "        print(\"Scanning dataset for image files...\")\n",
    "        \n",
    "        # Get all PNG files from pre-flood folder\n",
    "        pre_flood_files = [f for f in os.listdir(self.pre_flood_dir) if f.endswith('.png')]\n",
    "        pre_flood_files.sort()\n",
    "        \n",
    "        valid_images = []\n",
    "        missing_files = []\n",
    "        \n",
    "        for img_name in tqdm(pre_flood_files, desc=\"Verifying image triplets\"):\n",
    "            pre_path = os.path.join(self.pre_flood_dir, img_name)\n",
    "            post_path = os.path.join(self.post_flood_dir, img_name)\n",
    "            label_path = os.path.join(self.label_dir, img_name)\n",
    "            \n",
    "            # Check if all three files exist\n",
    "            if os.path.exists(pre_path) and os.path.exists(post_path) and os.path.exists(label_path):\n",
    "                valid_images.append(img_name)\n",
    "            else:\n",
    "                missing_files.append(img_name)\n",
    "                \n",
    "        print(f\"Found {len(valid_images)} valid image triplets\")\n",
    "        if missing_files:\n",
    "            print(f\"Warning: {len(missing_files)} images missing from one or more folders\")\n",
    "            print(f\"First few missing: {missing_files[:5]}\")\n",
    "            \n",
    "        return valid_images\n",
    "    \n",
    "    def create_data_splits(self, image_list):\n",
    "        \"\"\"Create train/validation/test splits and save them\"\"\"\n",
    "        print(f\"Creating data splits with random_state={self.random_state}\")\n",
    "        print(f\"Test size: {self.test_size}, Validation size: {self.val_size}\")\n",
    "        \n",
    "        # First split: separate test set\n",
    "        train_val_images, test_images = train_test_split(\n",
    "            image_list, \n",
    "            test_size=self.test_size, \n",
    "            random_state=self.random_state,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        # Second split: separate train and validation from remaining data\n",
    "        # Calculate validation size relative to train_val set\n",
    "        val_size_adjusted = self.val_size / (1 - self.test_size)\n",
    "        \n",
    "        train_images, val_images = train_test_split(\n",
    "            train_val_images,\n",
    "            test_size=val_size_adjusted,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        splits = {\n",
    "            'train': train_images,\n",
    "            'val': val_images,\n",
    "            'test': test_images\n",
    "        }\n",
    "        \n",
    "        # Print split information\n",
    "        print(f\"Data splits created:\")\n",
    "        print(f\"  Train: {len(train_images)} images ({len(train_images)/len(image_list)*100:.1f}%)\")\n",
    "        print(f\"  Validation: {len(val_images)} images ({len(val_images)/len(image_list)*100:.1f}%)\")\n",
    "        print(f\"  Test: {len(test_images)} images ({len(test_images)/len(image_list)*100:.1f}%)\")\n",
    "        \n",
    "        # Save splits to CSV files\n",
    "        splits_dir = os.path.join(self.output_path, 'splits')\n",
    "        \n",
    "        for split_name, images in splits.items():\n",
    "            csv_path = os.path.join(splits_dir, f'{split_name}_images.csv')\n",
    "            with open(csv_path, 'w', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(['image_name'])  # Header\n",
    "                for img_name in images:\n",
    "                    writer.writerow([img_name])\n",
    "            print(f\"Saved {split_name} split to {csv_path}\")\n",
    "        \n",
    "        # Save split info as JSON for reference\n",
    "        split_info = {\n",
    "            'total_images': len(image_list),\n",
    "            'splits': {\n",
    "                'train': {'count': len(train_images), 'percentage': len(train_images)/len(image_list)*100},\n",
    "                'val': {'count': len(val_images), 'percentage': len(val_images)/len(image_list)*100},\n",
    "                'test': {'count': len(test_images), 'percentage': len(test_images)/len(image_list)*100}\n",
    "            },\n",
    "            'random_state': self.random_state,\n",
    "            'test_size': self.test_size,\n",
    "            'val_size': self.val_size\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(splits_dir, 'split_info.json'), 'w') as f:\n",
    "            json.dump(split_info, f, indent=2)\n",
    "        \n",
    "        return splits\n",
    "    \n",
    "    def load_and_process_image(self, image_path):\n",
    "        \"\"\"Load and process a single image\"\"\"\n",
    "        try:\n",
    "            # Load image\n",
    "            img = Image.open(image_path)\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Resize if needed (though should already be 256x256)\n",
    "            if img.size != (self.img_size, self.img_size):\n",
    "                img = img.resize((self.img_size, self.img_size), Image.LANCZOS)\n",
    "            \n",
    "            # Convert to numpy array and normalize to [0, 1]\n",
    "            img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "            \n",
    "            return img_array\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def load_and_process_mask(self, mask_path):\n",
    "        \"\"\"Load and process a mask image\"\"\"\n",
    "        try:\n",
    "            # Load mask\n",
    "            mask = Image.open(mask_path)\n",
    "            \n",
    "            # Convert to grayscale if needed\n",
    "            if mask.mode != 'L':\n",
    "                mask = mask.convert('L')\n",
    "            \n",
    "            # Resize if needed\n",
    "            if mask.size != (self.img_size, self.img_size):\n",
    "                mask = mask.resize((self.img_size, self.img_size), Image.NEAREST)\n",
    "            \n",
    "            # Convert to numpy array and create binary mask\n",
    "            mask_array = np.array(mask, dtype=np.float32)\n",
    "            \n",
    "            # Normalize and threshold to create binary mask\n",
    "            mask_array = mask_array / 255.0  # Normalize to [0, 1]\n",
    "            mask_array = (mask_array > 0.5).astype(np.float32)  # Binary threshold\n",
    "            \n",
    "            return mask_array\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing mask {mask_path}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def update_stats(self, split, mask):\n",
    "        \"\"\"Update dataset statistics\"\"\"\n",
    "        self.stats[split]['count'] += 1\n",
    "        self.stats[split]['flood_pixels'] += mask.sum()\n",
    "        self.stats[split]['total_pixels'] += mask.size\n",
    "    \n",
    "    def process_split(self, split_name, image_list):\n",
    "        \"\"\"Process images for a specific split\"\"\"\n",
    "        print(f\"Processing {split_name} split...\")\n",
    "        \n",
    "        split_dir = os.path.join(self.output_path, split_name)\n",
    "        \n",
    "        for idx, img_name in enumerate(tqdm(image_list, desc=f\"Processing {split_name}\")):\n",
    "            # Define paths\n",
    "            pre_flood_path = os.path.join(self.pre_flood_dir, img_name)\n",
    "            post_flood_path = os.path.join(self.post_flood_dir, img_name)\n",
    "            mask_path = os.path.join(self.label_dir, img_name)\n",
    "            \n",
    "            # Process pre-flood image\n",
    "            pre_flood_array = self.load_and_process_image(pre_flood_path)\n",
    "            if pre_flood_array is None:\n",
    "                continue\n",
    "            \n",
    "            # Process post-flood image\n",
    "            post_flood_array = self.load_and_process_image(post_flood_path)\n",
    "            if post_flood_array is None:\n",
    "                continue\n",
    "            \n",
    "            # Process mask\n",
    "            mask_array = self.load_and_process_mask(mask_path)\n",
    "            if mask_array is None:\n",
    "                continue\n",
    "            \n",
    "            # Save processed images\n",
    "            base_name = os.path.splitext(img_name)[0]\n",
    "            \n",
    "            # Save as NPY files for exact precision\n",
    "            np.save(os.path.join(split_dir, 'pre_flood', f'{base_name}.npy'), pre_flood_array)\n",
    "            np.save(os.path.join(split_dir, 'post_flood', f'{base_name}.npy'), post_flood_array)\n",
    "            np.save(os.path.join(split_dir, 'masks', f'{base_name}.npy'), mask_array)\n",
    "            \n",
    "            # Also save as PNG for visualization\n",
    "            pre_flood_img = Image.fromarray((pre_flood_array * 255).astype(np.uint8))\n",
    "            post_flood_img = Image.fromarray((post_flood_array * 255).astype(np.uint8))\n",
    "            mask_img = Image.fromarray((mask_array * 255).astype(np.uint8), mode='L')\n",
    "            \n",
    "            pre_flood_img.save(os.path.join(split_dir, 'pre_flood', f'{base_name}.png'))\n",
    "            post_flood_img.save(os.path.join(split_dir, 'post_flood', f'{base_name}.png'))\n",
    "            mask_img.save(os.path.join(split_dir, 'masks', f'{base_name}.png'))\n",
    "            \n",
    "            # Update statistics\n",
    "            self.update_stats(split_name, mask_array)\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"Print dataset statistics\"\"\"\n",
    "        print(\"\\nDataset Statistics:\")\n",
    "        print(\"=\" * 50)\n",
    "        for split, stat in self.stats.items():\n",
    "            if stat['count'] > 0:\n",
    "                flood_percentage = 100 * stat['flood_pixels'] / stat['total_pixels']\n",
    "                print(f\"{split.upper()} set: {stat['count']} samples, \"\n",
    "                      f\"Flood pixels: {flood_percentage:.2f}%\")\n",
    "        print(\"=\" * 50)\n",
    "    \n",
    "    def calculate_class_weights(self):\n",
    "        \"\"\"Calculate class weights to handle imbalance\"\"\"\n",
    "        if self.stats['train']['total_pixels'] > 0:\n",
    "            pos_ratio = self.stats['train']['flood_pixels'] / self.stats['train']['total_pixels']\n",
    "            neg_ratio = 1 - pos_ratio\n",
    "            \n",
    "            # Class weights inversely proportional to class frequency\n",
    "            weight_non_flood = 1.0\n",
    "            weight_flood = neg_ratio / pos_ratio if pos_ratio > 0 else 1.0\n",
    "            \n",
    "            print(f\"\\nClass weights for handling imbalance:\")\n",
    "            print(f\"Weight for non-flood (0): {weight_non_flood:.4f}\")\n",
    "            print(f\"Weight for flood (1): {weight_flood:.4f}\")\n",
    "            \n",
    "            # Save weights for model training\n",
    "            return np.array([weight_non_flood, weight_flood])\n",
    "        return np.array([1.0, 1.0])\n",
    "    \n",
    "    def run_preprocessing(self):\n",
    "        \"\"\"Run the complete preprocessing pipeline\"\"\"\n",
    "        print(\"Starting Change Detection Flood Preprocessing...\")\n",
    "        print(f\"Input path: {self.base_path}\")\n",
    "        print(f\"Output path: {self.output_path}\")\n",
    "        print(f\"Expected image range: image_1.png to image_5360.png\")\n",
    "        print(f\"Image size: {self.img_size}x{self.img_size}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Step 1: Get list of valid images\n",
    "        image_list = self.get_image_list()\n",
    "        if len(image_list) == 0:\n",
    "            raise ValueError(\"No valid image triplets found!\")\n",
    "        \n",
    "        # Step 2: Create data splits\n",
    "        splits = self.create_data_splits(image_list)\n",
    "        \n",
    "        # Step 3: Process each split\n",
    "        for split_name, images in splits.items():\n",
    "            self.process_split(split_name, images)\n",
    "        \n",
    "        # Step 4: Print statistics and calculate class weights\n",
    "        self.print_stats()\n",
    "        weights = self.calculate_class_weights()\n",
    "        \n",
    "        # Step 5: Save class weights\n",
    "        weights_path = os.path.join(self.output_path, 'class_weights.npy')\n",
    "        np.save(weights_path, weights)\n",
    "        print(f\"\\nClass weights saved to: {weights_path}\")\n",
    "        \n",
    "        # Step 6: Save preprocessing info\n",
    "        preprocessing_info = {\n",
    "            'dataset_type': 'change_detection_flood',\n",
    "            'input_format': 'pre_flood + post_flood -> flood_mask',\n",
    "            'total_images': len(image_list),\n",
    "            'image_size': [self.img_size, self.img_size],\n",
    "            'splits': {\n",
    "                'train': len(splits['train']),\n",
    "                'val': len(splits['val']),\n",
    "                'test': len(splits['test'])\n",
    "            },\n",
    "            'random_state': self.random_state,\n",
    "            'class_weights': weights.tolist(),\n",
    "            'statistics': self.stats\n",
    "        }\n",
    "        \n",
    "        info_path = os.path.join(self.output_path, 'preprocessing_info.json')\n",
    "        with open(info_path, 'w') as f:\n",
    "            json.dump(preprocessing_info, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nPreprocessing complete! Processed data saved to: {self.output_path}\")\n",
    "        print(\"\\nOutput structure:\")\n",
    "        print(\"preprocessed/\")\n",
    "        print(\"├── train/\")\n",
    "        print(\"│   ├── pre_flood/ (NPY and PNG files)\")\n",
    "        print(\"│   ├── post_flood/ (NPY and PNG files)\")\n",
    "        print(\"│   └── masks/ (NPY and PNG files)\")\n",
    "        print(\"├── val/\")\n",
    "        print(\"│   ├── pre_flood/ (NPY and PNG files)\")\n",
    "        print(\"│   ├── post_flood/ (NPY and PNG files)\")\n",
    "        print(\"│   └── masks/ (NPY and PNG files)\")\n",
    "        print(\"├── test/\")\n",
    "        print(\"│   ├── pre_flood/ (NPY and PNG files)\")\n",
    "        print(\"│   ├── post_flood/ (NPY and PNG files)\")\n",
    "        print(\"│   └── masks/ (NPY and PNG files)\")\n",
    "        print(\"├── splits/\")\n",
    "        print(\"│   ├── train_images.csv\")\n",
    "        print(\"│   ├── val_images.csv\")\n",
    "        print(\"│   ├── test_images.csv\")\n",
    "        print(\"│   └── split_info.json\")\n",
    "        print(\"├── class_weights.npy\")\n",
    "        print(\"└── preprocessing_info.json\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "# Example usage for Kaggle environment\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Change Detection Flood Preprocessing for Kaggle Environment\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Kaggle paths\n",
    "    base_path = \"/kaggle/input/s1gfloods\"  # Contains A, B, Label folders\n",
    "    output_path = \"/kaggle/working/preprocessed_change_detection\"\n",
    "    \n",
    "    # Initialize and run preprocessor\n",
    "    preprocessor = ChangeDetectionFloodPreprocessor(\n",
    "        base_path=base_path,\n",
    "        output_path=output_path,\n",
    "        img_size=256,\n",
    "        test_size=0.15,    # 15% for test\n",
    "        val_size=0.15,     # 15% for validation \n",
    "        random_state=42    # For reproducible splits\n",
    "    )\n",
    "    \n",
    "    # Run preprocessing\n",
    "    preprocessor.run_preprocessing()\n",
    "    \n",
    "    print(\"\\nPreprocessing completed successfully!\")\n",
    "    print(\"Ready for training with change detection model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0307694",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import glob\n",
    "from tensorflow.keras import backend as K\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Comprehensive precision control and TensorFlow configuration\n",
    "def setup_tensorflow_for_stable_training():\n",
    "    \"\"\"Configure TensorFlow for stable float32 training with maximum stability\"\"\"\n",
    "    # 1. Explicitly reset and disable mixed precision at all levels\n",
    "    tf.keras.mixed_precision.set_global_policy('float32')\n",
    "    tf.keras.backend.set_floatx('float32')\n",
    "    \n",
    "    # 2. Configure TensorFlow to avoid XLA precision issues\n",
    "    tf.config.optimizer.set_experimental_options({\n",
    "        'auto_mixed_precision': False,\n",
    "        'disable_meta_optimizer': True,\n",
    "        'constant_folding': False,\n",
    "        'arithmetic_optimization': False,\n",
    "        'loop_optimization': False,\n",
    "        'function_optimization': False\n",
    "    })\n",
    "    \n",
    "    # 3. Disable JIT compilation which can cause precision issues\n",
    "    tf.config.optimizer.set_jit(False)\n",
    "    \n",
    "    # 4. Force CPU/GPU to use float32\n",
    "    tf.config.experimental.enable_tensor_float_32_execution(False)\n",
    "    \n",
    "    # 5. Set memory growth and device policy to avoid GPU/CPU conflicts\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"GPU configuration warning: {e}\")\n",
    "    \n",
    "    # 6. CRITICAL: Set device policy to handle CPU/GPU tensor placement issues\n",
    "    tf.config.experimental.set_device_policy('silent')\n",
    "    \n",
    "    # 7. Additional precision controls\n",
    "    import os\n",
    "    os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '0'\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduce log spam\n",
    "    \n",
    "    print(\"TensorFlow configured for maximum stability float32 training\")\n",
    "    print(\"- Mixed precision: Completely disabled\")\n",
    "    print(\"- XLA JIT: Disabled\")\n",
    "    print(\"- TF32: Disabled\") \n",
    "    print(\"- Auto mixed precision: Disabled\")\n",
    "    print(\"- All optimizations: Disabled for stability\")\n",
    "    print(\"- Device policy: Silent (handles CPU/GPU conflicts)\")\n",
    "    print(\"- Default dtype: float32\")\n",
    "\n",
    "# Apply comprehensive TensorFlow configuration\n",
    "setup_tensorflow_for_stable_training()\n",
    "\n",
    "# Define paths\n",
    "BASE_PATH = \"/kaggle/working/preprocessed_change_detection\"\n",
    "OUTPUT_PATH = \"/kaggle/working/flood_change_detection_model\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Define helper functions for data loading (CHANGE DETECTION VERSION)\n",
    "def load_image_pair(pre_flood_path, post_flood_path):\n",
    "    \"\"\"Load and concatenate pre-flood and post-flood images with consistent float32 precision\"\"\"\n",
    "    # Convert tensor to string if needed\n",
    "    if isinstance(pre_flood_path, tf.Tensor):\n",
    "        pre_flood_path = pre_flood_path.numpy().decode('utf-8')\n",
    "    if isinstance(post_flood_path, tf.Tensor):\n",
    "        post_flood_path = post_flood_path.numpy().decode('utf-8')\n",
    "    \n",
    "    # Load both images\n",
    "    pre_flood = np.load(pre_flood_path).astype(np.float32)\n",
    "    post_flood = np.load(post_flood_path).astype(np.float32)\n",
    "    \n",
    "    # Concatenate along channel dimension to create 6-channel input\n",
    "    # Pre-flood: channels 0-2, Post-flood: channels 3-5\n",
    "    combined_image = np.concatenate([pre_flood, post_flood], axis=-1)\n",
    "    \n",
    "    return combined_image\n",
    "\n",
    "def load_mask(mask_path):\n",
    "    \"\"\"Load mask from .npy file with consistent float32 precision\"\"\"\n",
    "    # Convert tensor to string if needed\n",
    "    if isinstance(mask_path, tf.Tensor):\n",
    "        mask_path = mask_path.numpy().decode('utf-8')\n",
    "    \n",
    "    mask = np.load(mask_path).astype(np.float32)\n",
    "    return mask\n",
    "\n",
    "# Enhanced data augmentation for change detection\n",
    "def enhanced_change_detection_augmentation():\n",
    "    \"\"\"Enhanced data augmentation for change detection with float32 precision\"\"\"\n",
    "    def augment_fn(image, mask):\n",
    "        # Ensure float32 precision at the start\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        \n",
    "        # Random horizontal flip (apply to both pre and post images)\n",
    "        if tf.random.uniform([]) > 0.5:\n",
    "            image = tf.image.flip_left_right(image)\n",
    "            mask = tf.image.flip_left_right(mask)\n",
    "        \n",
    "        # Random vertical flip\n",
    "        if tf.random.uniform([]) > 0.5:\n",
    "            image = tf.image.flip_up_down(image)\n",
    "            mask = tf.image.flip_up_down(mask)\n",
    "        \n",
    "        # Random rotation (90, 180, 270 degrees)\n",
    "        k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n",
    "        image = tf.image.rot90(image, k)\n",
    "        mask = tf.image.rot90(mask, k)\n",
    "        \n",
    "        # Random brightness adjustment (apply to both images)\n",
    "        if tf.random.uniform([]) > 0.7:\n",
    "            # Apply same brightness change to both pre and post flood images\n",
    "            brightness_delta = tf.random.uniform([], -0.1, 0.1)\n",
    "            image = tf.clip_by_value(image + brightness_delta, 0.0, 1.0)\n",
    "        \n",
    "        # Random contrast adjustment (apply to both images)\n",
    "        if tf.random.uniform([]) > 0.7:\n",
    "            contrast_factor = tf.random.uniform([], 0.9, 1.1)\n",
    "            image = tf.clip_by_value(image * contrast_factor, 0.0, 1.0)\n",
    "        \n",
    "        # Gaussian noise (simulate sensor noise)\n",
    "        if tf.random.uniform([]) > 0.6:\n",
    "            noise = tf.random.normal(tf.shape(image), mean=0, stddev=0.01)\n",
    "            image = tf.clip_by_value(image + noise, 0.0, 1.0)\n",
    "        \n",
    "        # Ensure outputs are float32\n",
    "        return tf.cast(image, tf.float32), tf.cast(mask, tf.float32)\n",
    "    \n",
    "    return augment_fn\n",
    "\n",
    "def create_change_detection_dataset(base_path, split, batch_size=32, shuffle=True, use_augmentation=False):\n",
    "    \"\"\"Create a TensorFlow dataset for change detection\"\"\"\n",
    "    pre_flood_paths = sorted(glob.glob(os.path.join(base_path, split, 'pre_flood', '*.npy')))\n",
    "    post_flood_paths = sorted(glob.glob(os.path.join(base_path, split, 'post_flood', '*.npy')))\n",
    "    mask_paths = sorted(glob.glob(os.path.join(base_path, split, 'masks', '*.npy')))\n",
    "    \n",
    "    if len(pre_flood_paths) == 0 or len(post_flood_paths) == 0 or len(mask_paths) == 0:\n",
    "        raise ValueError(f\"No images found in {base_path}/{split}\")\n",
    "    \n",
    "    if not (len(pre_flood_paths) == len(post_flood_paths) == len(mask_paths)):\n",
    "        raise ValueError(f\"Mismatch in number of images: pre={len(pre_flood_paths)}, post={len(post_flood_paths)}, masks={len(mask_paths)}\")\n",
    "    \n",
    "    print(f\"Found {len(pre_flood_paths)} image pairs and masks for {split}\")\n",
    "    \n",
    "    # Create datasets from paths\n",
    "    pre_flood_dataset = tf.data.Dataset.from_tensor_slices(pre_flood_paths)\n",
    "    post_flood_dataset = tf.data.Dataset.from_tensor_slices(post_flood_paths)\n",
    "    mask_dataset = tf.data.Dataset.from_tensor_slices(mask_paths)\n",
    "    \n",
    "    # Combine all paths\n",
    "    dataset = tf.data.Dataset.zip((pre_flood_dataset, post_flood_dataset, mask_dataset))\n",
    "    \n",
    "    # Shuffle if needed\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(pre_flood_paths), seed=42)\n",
    "    \n",
    "    # Map loading function to the dataset\n",
    "    dataset = dataset.map(\n",
    "        lambda pre_path, post_path, mask_path: (\n",
    "            tf.py_function(\n",
    "                func=load_image_pair,\n",
    "                inp=[pre_path, post_path],\n",
    "                Tout=tf.float32\n",
    "            ),\n",
    "            tf.py_function(\n",
    "                func=load_mask,\n",
    "                inp=[mask_path],\n",
    "                Tout=tf.float32\n",
    "            )\n",
    "        ),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    # Set shapes and ensure float32 precision\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: (\n",
    "            tf.ensure_shape(tf.cast(x, tf.float32), [256, 256, 6]),  # 6 channels now\n",
    "            tf.ensure_shape(tf.cast(y, tf.float32), [256, 256])\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add channel dimension to mask and ensure float32 precision\n",
    "    dataset = dataset.map(lambda x, y: (\n",
    "        tf.cast(x, tf.float32), \n",
    "        tf.cast(tf.expand_dims(y, axis=-1), tf.float32)\n",
    "    ))\n",
    "    \n",
    "    # Apply data augmentation only for training\n",
    "    if use_augmentation and split == 'train':\n",
    "        augment_fn = enhanced_change_detection_augmentation()\n",
    "        dataset = dataset.map(augment_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Important: Add repeat to prevent dataset exhaustion\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Batch and prefetch\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset, len(pre_flood_paths)\n",
    "\n",
    "def visualize_change_detection_samples(dataset, num_samples=3):\n",
    "    \"\"\"Visualize random samples from the change detection dataset\"\"\"\n",
    "    plt.figure(figsize=(20, 5*num_samples))\n",
    "    \n",
    "    for i, (images, masks) in enumerate(dataset.take(num_samples)):\n",
    "        for j in range(min(images.shape[0], 1)):  # Show one sample per batch\n",
    "            # Get image and mask\n",
    "            image = images[j].numpy()\n",
    "            mask = masks[j].numpy().squeeze()\n",
    "            \n",
    "            # Split the 6-channel image back to pre and post flood\n",
    "            pre_flood = image[:, :, :3]  # First 3 channels\n",
    "            post_flood = image[:, :, 3:]  # Last 3 channels\n",
    "            \n",
    "            # Display pre-flood image\n",
    "            plt.subplot(num_samples, 4, i*4+1)\n",
    "            plt.imshow(pre_flood)\n",
    "            plt.title(f\"Pre-Flood - Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Display post-flood image\n",
    "            plt.subplot(num_samples, 4, i*4+2)\n",
    "            plt.imshow(post_flood)\n",
    "            plt.title(f\"Post-Flood - Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Display difference image\n",
    "            difference = np.abs(post_flood - pre_flood)\n",
    "            plt.subplot(num_samples, 4, i*4+3)\n",
    "            plt.imshow(difference)\n",
    "            plt.title(f\"Difference - Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Display mask\n",
    "            plt.subplot(num_samples, 4, i*4+4)\n",
    "            plt.imshow(mask, cmap='Blues')\n",
    "            plt.title(f\"Flood Mask - Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'change_detection_samples.png'))\n",
    "    plt.show()\n",
    "\n",
    "# Define custom metrics with consistent float32 casting (same as before)\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate Dice coefficient with consistent float32 precision\"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    result = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return tf.cast(result, tf.float32)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Dice loss function based on dice coefficient with consistent float32 precision\"\"\"\n",
    "    return tf.cast(1 - dice_coefficient(y_true, y_pred, smooth), tf.float32)\n",
    "\n",
    "def optimized_focal_tversky_loss(y_true, y_pred, alpha=0.7, beta=0.3, gamma=1.5, smooth=1e-6):\n",
    "    \"\"\"Optimized Focal Tversky Loss for maximum IoU\"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    \n",
    "    true_pos = K.sum(y_true_f * y_pred_f)\n",
    "    false_neg = K.sum(y_true_f * (1 - y_pred_f))\n",
    "    false_pos = K.sum((1 - y_true_f) * y_pred_f)\n",
    "    \n",
    "    tversky = (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
    "    focal_tversky = K.pow((1 - tversky), gamma)\n",
    "    \n",
    "    return tf.cast(focal_tversky, tf.float32)\n",
    "\n",
    "def iou_score(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate IoU (Intersection over Union) score with consistent float32 precision\"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    result = (intersection + smooth) / (union + smooth)\n",
    "    return tf.cast(result, tf.float32)\n",
    "\n",
    "def f1_score_metric(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate F1 score metric with consistent float32 precision\"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f)\n",
    "    predicted_positives = K.sum(y_pred_f)\n",
    "    actual_positives = K.sum(y_true_f)\n",
    "\n",
    "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + smooth)\n",
    "    return tf.cast(f1, tf.float32)\n",
    "\n",
    "def precision_metric(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate precision metric with consistent float32 precision\"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f)\n",
    "    predicted_positives = K.sum(y_pred_f)\n",
    "\n",
    "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "    return tf.cast(precision, tf.float32)\n",
    "\n",
    "def recall_metric(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate recall metric with consistent float32 precision\"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f)\n",
    "    actual_positives = K.sum(y_true_f)\n",
    "\n",
    "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "    return tf.cast(recall, tf.float32)\n",
    "\n",
    "# Modified ResUNet architecture for 6-channel input (CHANGE DETECTION)\n",
    "def conv_block(inputs, filters, kernel_size=3, strides=1, padding='same'):\n",
    "    \"\"\"Convolutional block with batch normalization and activation - explicit float32\"\"\"\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding, dtype='float32')(inputs)\n",
    "    x = layers.BatchNormalization(dtype='float32')(x)\n",
    "    x = layers.ReLU(dtype='float32')(x)\n",
    "    return x\n",
    "\n",
    "def multi_scale_context_module(inputs):\n",
    "    \"\"\"Multi-scale context module using dilated convolutions\"\"\"\n",
    "    channels = inputs.shape[-1]\n",
    "    \n",
    "    # Original features\n",
    "    branch1 = inputs\n",
    "    \n",
    "    # Dilated convolutions for multi-scale context\n",
    "    branch2 = layers.Conv2D(channels // 4, 3, padding='same', dilation_rate=2, activation='relu')(inputs)\n",
    "    branch3 = layers.Conv2D(channels // 4, 3, padding='same', dilation_rate=4, activation='relu')(inputs)\n",
    "    branch4 = layers.Conv2D(channels // 4, 3, padding='same', dilation_rate=8, activation='relu')(inputs)\n",
    "    \n",
    "    # Global context using 1x1 conv\n",
    "    global_context = layers.GlobalAveragePooling2D()(inputs)\n",
    "    global_context = layers.Dense(channels // 4, activation='relu')(global_context)\n",
    "    global_context = layers.RepeatVector(inputs.shape[1] * inputs.shape[2])(global_context)\n",
    "    global_context = layers.Reshape((inputs.shape[1], inputs.shape[2], channels // 4))(global_context)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    concatenated = layers.Concatenate()([branch1, branch2, branch3, branch4, global_context])\n",
    "    \n",
    "    # Reduce channels back to original\n",
    "    output = layers.Conv2D(channels, 1, activation='relu', padding='same')(concatenated)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def channel_attention(inputs, ratio=16):\n",
    "    \"\"\"Enhanced Squeeze and Excitation Block for channel attention with explicit float32\"\"\"\n",
    "    channels = int(inputs.shape[-1])\n",
    "    reduced_channels = max(channels // ratio, 8)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D(dtype='float32')(inputs)\n",
    "    x = layers.Reshape((1, 1, channels))(x)\n",
    "    x = layers.Conv2D(reduced_channels, kernel_size=1, activation='elu', padding='same', dtype='float32')(x)\n",
    "    x = layers.Dropout(0.1, dtype='float32')(x)\n",
    "    x = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same', dtype='float32')(x)\n",
    "    \n",
    "    output = layers.Multiply(dtype='float32')([inputs, x])\n",
    "    return output\n",
    "\n",
    "class ChannelMean(layers.Layer):\n",
    "    \"\"\"Custom layer to compute channel-wise mean - safer than Lambda\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ChannelMean, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(ChannelMean, self).get_config()\n",
    "\n",
    "class ChannelMax(layers.Layer):\n",
    "    \"\"\"Custom layer to compute channel-wise max - safer than Lambda\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ChannelMax, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.reduce_max(inputs, axis=-1, keepdims=True)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(ChannelMax, self).get_config()\n",
    "\n",
    "def spatial_attention(inputs):\n",
    "    \"\"\"Enhanced spatial attention module with custom layers instead of Lambda\"\"\"\n",
    "    avg_pool = ChannelMean(dtype='float32')(inputs)\n",
    "    max_pool = ChannelMax(dtype='float32')(inputs)\n",
    "    \n",
    "    concat = layers.Concatenate(axis=-1, dtype='float32')([avg_pool, max_pool])\n",
    "    attention_map = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid', dtype='float32')(concat)\n",
    "    \n",
    "    output = layers.Multiply(dtype='float32')([inputs, attention_map])\n",
    "    return output\n",
    "\n",
    "def attention_residual_block(inputs, filters, kernel_size=3, strides=1, dropout_rate=0.1):\n",
    "    \"\"\"Enhanced residual block with channel and spatial attention\"\"\"\n",
    "    x = conv_block(inputs, filters, kernel_size, strides)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = conv_block(x, filters, kernel_size, 1)\n",
    "    \n",
    "    x = channel_attention(x)\n",
    "    x = spatial_attention(x)\n",
    "    \n",
    "    if strides > 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "    \n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_change_detection_resunet(input_shape=(256, 256, 6), num_classes=1):\n",
    "    \"\"\"Build Change Detection ResUNet model - 6 channel input for pre+post flood images\"\"\"\n",
    "    # Input layer with explicit dtype - 6 channels for change detection\n",
    "    inputs = layers.Input(input_shape, dtype='float32')\n",
    "    \n",
    "    # Optional: Add a layer to process the change information explicitly\n",
    "    # This helps the model understand the temporal relationship\n",
    "    change_features = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu', dtype='float32')(inputs)\n",
    "    change_features = layers.BatchNormalization(dtype='float32')(change_features)\n",
    "    \n",
    "    # Initial Convolution with larger kernel for better feature extraction\n",
    "    x = conv_block(change_features, 64, kernel_size=7, strides=1)\n",
    "\n",
    "    # Encoder blocks with residual connections and max pooling\n",
    "    # Encoder block 1\n",
    "    skip1 = simple_attention_residual_block(x, 64, dropout_rate=0.1)\n",
    "    x = layers.MaxPooling2D(2, dtype='float32')(skip1)\n",
    "\n",
    "    # Encoder block 2\n",
    "    skip2 = simple_attention_residual_block(x, 128, dropout_rate=0.1)\n",
    "    x = layers.MaxPooling2D(2, dtype='float32')(skip2)\n",
    "\n",
    "    # Encoder block 3\n",
    "    skip3 = simple_attention_residual_block(x, 256, dropout_rate=0.15)\n",
    "    x = layers.MaxPooling2D(2, dtype='float32')(skip3)\n",
    "\n",
    "    # Enhanced Bridge with Multi-scale Context\n",
    "    x = simple_attention_residual_block(x, 512, dropout_rate=0.2)\n",
    "    x = multi_scale_context_module(x)\n",
    "\n",
    "    # Decoder blocks with upsampling and concatenation with skip connections\n",
    "    # Decoder block 1\n",
    "    x = layers.UpSampling2D(2, interpolation='bilinear', dtype='float32')(x)\n",
    "    x = conv_block(x, 256)\n",
    "    x = layers.Concatenate(dtype='float32')([x, skip3])\n",
    "    x = simple_attention_residual_block(x, 256, dropout_rate=0.15)\n",
    "\n",
    "    # Decoder block 2\n",
    "    x = layers.UpSampling2D(2, interpolation='bilinear', dtype='float32')(x)\n",
    "    x = conv_block(x, 128)\n",
    "    x = layers.Concatenate(dtype='float32')([x, skip2])\n",
    "    x = simple_attention_residual_block(x, 128, dropout_rate=0.1)\n",
    "\n",
    "    # Decoder block 3\n",
    "    x = layers.UpSampling2D(2, interpolation='bilinear', dtype='float32')(x)\n",
    "    x = conv_block(x, 64)\n",
    "    x = layers.Concatenate(dtype='float32')([x, skip1])\n",
    "    x = simple_attention_residual_block(x, 64, dropout_rate=0.1)\n",
    "\n",
    "    # Output layer with explicit float32\n",
    "    outputs = layers.Conv2D(num_classes, kernel_size=1, activation='sigmoid', dtype='float32')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def simple_spatial_attention(inputs):\n",
    "    \"\"\"Simple spatial attention without Lambda layers\"\"\"\n",
    "    # Use custom layers instead of Lambda\n",
    "    avg_pool = ChannelMean(dtype='float32')(inputs)\n",
    "    max_pool = ChannelMax(dtype='float32')(inputs)\n",
    "    \n",
    "    concat = layers.Concatenate(axis=-1, dtype='float32')([avg_pool, max_pool])\n",
    "    attention_map = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid', dtype='float32')(concat)\n",
    "    \n",
    "    output = layers.Multiply(dtype='float32')([inputs, attention_map])\n",
    "    return output\n",
    "\n",
    "def simple_attention_residual_block(inputs, filters, kernel_size=3, strides=1, dropout_rate=0.1):\n",
    "    \"\"\"Simple residual block with attention - no Lambda layers\"\"\"\n",
    "    x = conv_block(inputs, filters, kernel_size, strides)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = conv_block(x, filters, kernel_size, 1)\n",
    "    \n",
    "    x = channel_attention(x)\n",
    "    x = simple_spatial_attention(x)  # Use the Lambda-free version\n",
    "    \n",
    "    if strides > 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "    \n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_simple_change_detection_resunet(input_shape=(256, 256, 6), num_classes=1):\n",
    "    \"\"\"Build a simpler Change Detection ResUNet model as fallback - no Lambda layers\"\"\"\n",
    "    inputs = layers.Input(input_shape, dtype='float32')\n",
    "\n",
    "    # Encoder\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, 3, padding='same', dtype='float32')(inputs)\n",
    "    x = layers.BatchNormalization(dtype='float32')(x)\n",
    "    x = layers.ReLU(dtype='float32')(x)\n",
    "    skip1 = x\n",
    "    x = layers.MaxPooling2D(2, dtype='float32')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, 3, padding='same', dtype='float32')(x)\n",
    "    x = layers.BatchNormalization(dtype='float32')(x)\n",
    "    x = layers.ReLU(dtype='float32')(x)\n",
    "    skip2 = x\n",
    "    x = layers.MaxPooling2D(2, dtype='float32')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, 3, padding='same', dtype='float32')(x)\n",
    "    x = layers.BatchNormalization(dtype='float32')(x)\n",
    "    x = layers.ReLU(dtype='float32')(x)\n",
    "    skip3 = x\n",
    "    x = layers.MaxPooling2D(2, dtype='float32')(x)\n",
    "\n",
    "    # Bridge\n",
    "    x = layers.Conv2D(512, 3, padding='same', dtype='float32')(x)\n",
    "    x = layers.BatchNormalization(dtype='float32')(x)\n",
    "    x = layers.ReLU(dtype='float32')(x)\n",
    "\n",
    "    # Decoder\n",
    "    # Block 1\n",
    "    x = layers.UpSampling2D(2, dtype='float32')(x)\n",
    "    x = layers.Concatenate(dtype='float32')([x, skip3])\n",
    "    x = layers.Conv2D(256, 3, padding='same', dtype='float32')(x)\n",
    "    x = layers.BatchNormalization(dtype='float32')(x)\n",
    "    x = layers.ReLU(dtype='float32')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.UpSampling2D(2, dtype='float32')(x)\n",
    "    x = layers.Concatenate(dtype='float32')([x, skip2])\n",
    "    x = layers.Conv2D(128, 3, padding='same', dtype='float32')(x)\n",
    "    x = layers.BatchNormalization(dtype='float32')(x)\n",
    "    x = layers.ReLU(dtype='float32')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.UpSampling2D(2, dtype='float32')(x)\n",
    "    x = layers.Concatenate(dtype='float32')([x, skip1])\n",
    "    x = layers.Conv2D(64, 3, padding='same', dtype='float32')(x)\n",
    "    x = layers.BatchNormalization(dtype='float32')(x)\n",
    "    x = layers.ReLU(dtype='float32')(x)\n",
    "\n",
    "    # Output\n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='sigmoid', dtype='float32')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Advanced Learning Rate Scheduling (same as before)\n",
    "def warmup_cosine_schedule(epoch, warmup_epochs=15, total_epochs=150, base_lr=0.001, min_lr=1e-7):\n",
    "    \"\"\"Warmup + Cosine annealing learning rate schedule function\"\"\"\n",
    "    if epoch < warmup_epochs:\n",
    "        lr = base_lr * (epoch + 1) / warmup_epochs\n",
    "    else:\n",
    "        progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
    "        lr = min_lr + (base_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "    \n",
    "    return lr\n",
    "\n",
    "def get_optimized_callbacks(output_path, total_epochs=150):\n",
    "    \"\"\"Get optimized callbacks for maximum IoU performance\"\"\"\n",
    "    \n",
    "    callbacks_list = [\n",
    "        callbacks.LearningRateScheduler(\n",
    "            lambda epoch: warmup_cosine_schedule(\n",
    "                epoch, \n",
    "                warmup_epochs=15, \n",
    "                total_epochs=total_epochs, \n",
    "                base_lr=0.001, \n",
    "                min_lr=1e-7\n",
    "            ),\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(output_path, \"best_iou_change_detection_model.keras\"),\n",
    "            monitor='val_iou_score',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1,\n",
    "            save_weights_only=False\n",
    "        ),\n",
    "        \n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(output_path, \"best_dice_change_detection_model.keras\"),\n",
    "            monitor='val_iou_score',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1,\n",
    "            save_weights_only=False\n",
    "        ),\n",
    "        \n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_iou_score',\n",
    "            patience=40,\n",
    "            restore_best_weights=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_iou_score',\n",
    "            factor=0.5,\n",
    "            patience=12,\n",
    "            min_lr=1e-8,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        callbacks.TensorBoard(\n",
    "            log_dir=os.path.join(output_path, \"logs\"),\n",
    "            histogram_freq=1,\n",
    "            update_freq='epoch',\n",
    "            write_graph=True,\n",
    "            write_images=True,\n",
    "            profile_batch=0\n",
    "        ),\n",
    "        \n",
    "        callbacks.CSVLogger(\n",
    "            os.path.join(output_path, 'change_detection_training_log.csv'),\n",
    "            separator=',',\n",
    "            append=False\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks_list\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"Plot comprehensive training history with all metrics\"\"\"\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot Dice coefficient\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(history.history['dice_coefficient'], label='Training Dice')\n",
    "    plt.plot(history.history['val_dice_coefficient'], label='Validation Dice')\n",
    "    plt.title('Dice Coefficient')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot IoU\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.plot(history.history['iou_score'], label='Training IoU')\n",
    "    plt.plot(history.history['val_iou_score'], label='Validation IoU')\n",
    "    plt.title('IoU Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot binary accuracy\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.plot(history.history['binary_accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_binary_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Binary Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot F1 Score\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.plot(history.history['f1_score_metric'], label='Training F1')\n",
    "    plt.plot(history.history['val_f1_score_metric'], label='Validation F1')\n",
    "    plt.title('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot Precision and Recall\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.plot(history.history['precision_metric'], label='Training Precision')\n",
    "    plt.plot(history.history['val_precision_metric'], label='Validation Precision')\n",
    "    plt.plot(history.history['recall_metric'], label='Training Recall')\n",
    "    plt.plot(history.history['val_recall_metric'], label='Validation Recall')\n",
    "    plt.title('Precision and Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'change_detection_training_history.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_change_detection_predictions(model, dataset, num_samples=5):\n",
    "    \"\"\"Visualize change detection model predictions against ground truth\"\"\"\n",
    "    plt.figure(figsize=(20, 5*num_samples))\n",
    "\n",
    "    for i, (images, masks) in enumerate(dataset.take(num_samples)):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "\n",
    "        preds = model.predict(images, verbose=0)\n",
    "\n",
    "        for j in range(min(images.shape[0], 1)):  # Show one per batch\n",
    "            image = images[j].numpy()\n",
    "            mask = masks[j].numpy()\n",
    "            pred = preds[j]\n",
    "\n",
    "            # Split the 6-channel image back to pre and post flood\n",
    "            pre_flood = image[:, :, :3]\n",
    "            post_flood = image[:, :, 3:]\n",
    "\n",
    "            # Calculate difference\n",
    "            difference = np.abs(post_flood - pre_flood)\n",
    "\n",
    "            # Convert masks to binary\n",
    "            mask_binary = (mask > 0.5).astype(np.float32)\n",
    "            pred_binary = (pred > 0.5).astype(np.float32)\n",
    "\n",
    "            # Calculate metrics for this sample\n",
    "            dice = np.sum(2 * mask_binary * pred_binary) / (np.sum(mask_binary) + np.sum(pred_binary) + 1e-8)\n",
    "\n",
    "            row_idx = i\n",
    "\n",
    "            # Plot pre-flood image\n",
    "            plt.subplot(num_samples, 5, row_idx * 5 + 1)\n",
    "            plt.imshow(pre_flood)\n",
    "            plt.title(f\"Pre-Flood - Sample {row_idx+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Plot post-flood image\n",
    "            plt.subplot(num_samples, 5, row_idx * 5 + 2)\n",
    "            plt.imshow(post_flood)\n",
    "            plt.title(f\"Post-Flood - Sample {row_idx+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Plot difference\n",
    "            plt.subplot(num_samples, 5, row_idx * 5 + 3)\n",
    "            plt.imshow(difference)\n",
    "            plt.title(f\"Difference - Sample {row_idx+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Plot ground truth mask\n",
    "            plt.subplot(num_samples, 5, row_idx * 5 + 4)\n",
    "            plt.imshow(mask.squeeze(), cmap='Blues')\n",
    "            plt.title(f\"Ground Truth\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Plot prediction\n",
    "            plt.subplot(num_samples, 5, row_idx * 5 + 5)\n",
    "            plt.imshow(pred.squeeze(), cmap='Blues')\n",
    "            plt.title(f\"Prediction (Dice={dice:.3f})\")\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'change_detection_predictions.png'))\n",
    "    plt.show()\n",
    "\n",
    "def calculate_metrics(model, dataset, num_batches=None, threshold=0.5):\n",
    "    \"\"\"Calculate comprehensive metrics on dataset with pixel-level and image-level evaluation\"\"\"\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "\n",
    "    image_metrics = []\n",
    "    batch_count = 0\n",
    "    \n",
    "    for images, masks in dataset:\n",
    "        if num_batches is not None and batch_count >= num_batches:\n",
    "            break\n",
    "            \n",
    "        batch_count += 1\n",
    "        \n",
    "        preds = model.predict(images, verbose=0)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            mask = masks[i].numpy()\n",
    "            pred = preds[i]\n",
    "\n",
    "            mask_flat = mask.flatten()\n",
    "            pred_flat = pred.flatten()\n",
    "\n",
    "            pred_binary = (pred_flat > threshold).astype(np.int32)\n",
    "            mask_binary = (mask_flat > threshold).astype(np.int32)\n",
    "\n",
    "            y_true_all.extend(mask_binary)\n",
    "            y_pred_all.extend(pred_binary)\n",
    "\n",
    "            # Calculate per-image Dice\n",
    "            intersection = np.sum(mask_binary * pred_binary)\n",
    "            dice = (2. * intersection) / (np.sum(mask_binary) + np.sum(pred_binary) + 1e-8)\n",
    "            dice_scores.append(dice)\n",
    "\n",
    "            # Calculate per-image IoU\n",
    "            union = np.sum(mask_binary) + np.sum(pred_binary) - intersection\n",
    "            iou = intersection / (union + 1e-8)\n",
    "            iou_scores.append(iou)\n",
    "\n",
    "            # Per-image confusion matrix\n",
    "            img_tn, img_fp, img_fn, img_tp = confusion_matrix(mask_binary, pred_binary, labels=[0, 1]).ravel()\n",
    "\n",
    "            # Per-image metrics\n",
    "            img_precision = img_tp / (img_tp + img_fp + 1e-8)\n",
    "            img_recall = img_tp / (img_tp + img_fn + 1e-8)\n",
    "            img_f1 = 2 * (img_precision * img_recall) / (img_precision + img_recall + 1e-8)\n",
    "            img_accuracy = (img_tp + img_tn) / (img_tp + img_tn + img_fp + img_fn)\n",
    "\n",
    "            image_metrics.append({\n",
    "                'dice': dice,\n",
    "                'iou': iou,\n",
    "                'precision': img_precision,\n",
    "                'recall': img_recall,\n",
    "                'f1': img_f1,\n",
    "                'accuracy': img_accuracy,\n",
    "                'tp': int(img_tp),\n",
    "                'fp': int(img_fp),\n",
    "                'tn': int(img_tn),\n",
    "                'fn': int(img_fn)\n",
    "            })\n",
    "\n",
    "    # Calculate overall metrics from all pixels\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all, labels=[0, 1]).ravel()\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    specificity = tn / (tn + fp + 1e-8)\n",
    "\n",
    "    intersection = tp\n",
    "    union = tp + fp + fn\n",
    "    iou = intersection / (union + 1e-8)\n",
    "\n",
    "    mean_dice = np.mean(dice_scores)\n",
    "    mean_iou = np.mean(iou_scores)\n",
    "\n",
    "    print(\"\\n======== Change Detection Metrics ========\")\n",
    "    print(f\"Overall Metrics (pixel-level):\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall/Sensitivity: {recall:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"IoU: {iou:.4f}\")\n",
    "    print(f\"Dice Coefficient: {(2 * tp) / (2 * tp + fp + fn + 1e-8):.4f}\")\n",
    "\n",
    "    print(\"\\nMean Per-Image Metrics:\")\n",
    "    print(f\"Mean Dice: {mean_dice:.4f}\")\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "\n",
    "    # Save per-image metrics to CSV\n",
    "    img_metrics_df = pd.DataFrame(image_metrics)\n",
    "    img_metrics_df.to_csv(os.path.join(OUTPUT_PATH, 'change_detection_per_image_metrics.csv'), index_label='image_id')\n",
    "    print(\"\\nPer-image metrics saved to CSV file\")\n",
    "\n",
    "    return {\n",
    "        'overall': {\n",
    "            'accuracy': float(accuracy),\n",
    "            'precision': float(precision),\n",
    "            'recall': float(recall),\n",
    "            'specificity': float(specificity),\n",
    "            'f1': float(f1),\n",
    "            'iou': float(iou),\n",
    "            'dice': float((2 * tp) / (2 * tp + fp + fn + 1e-8))\n",
    "        },\n",
    "        'per_image_mean': {\n",
    "            'dice': float(mean_dice),\n",
    "            'iou': float(mean_iou)\n",
    "        },\n",
    "        'confusion_matrix': {\n",
    "            'tn': int(tn),\n",
    "            'fp': int(fp),\n",
    "            'fn': int(fn),\n",
    "            'tp': int(tp)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Main execution for Change Detection Training\n",
    "BATCH_SIZE = 24\n",
    "EPOCHS = 50\n",
    "USE_AUGMENTATION = True\n",
    "\n",
    "print(\"=== CHANGE DETECTION FLOOD TRAINING ===\")\n",
    "print(f\"Configuration:\")\n",
    "print(f\"- Input: Pre-flood + Post-flood images (6 channels)\")\n",
    "print(f\"- Output: Flood detection mask\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"- Total Epochs: {EPOCHS}\")\n",
    "print(f\"- Data Augmentation: {USE_AUGMENTATION}\")\n",
    "print(f\"- Architecture: Enhanced ResUNet for Change Detection\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create datasets for change detection\n",
    "train_dataset, train_size = create_change_detection_dataset(\n",
    "    BASE_PATH, 'train', \n",
    "    batch_size=BATCH_SIZE, \n",
    "    use_augmentation=USE_AUGMENTATION\n",
    ")\n",
    "val_dataset, val_size = create_change_detection_dataset(\n",
    "    BASE_PATH, 'val', \n",
    "    batch_size=BATCH_SIZE, \n",
    "    use_augmentation=False\n",
    ")\n",
    "test_dataset, test_size = create_change_detection_dataset(\n",
    "    BASE_PATH, 'test', \n",
    "    batch_size=BATCH_SIZE, \n",
    "    use_augmentation=False\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {train_size} image pairs\")\n",
    "print(f\"Validation dataset size: {val_size} image pairs\")\n",
    "print(f\"Test dataset size: {test_size} image pairs\")\n",
    "\n",
    "# Visualize some samples\n",
    "visualize_change_detection_samples(train_dataset, num_samples=2)\n",
    "\n",
    "# Build change detection model\n",
    "input_shape = (256, 256, 6)  # 6 channels for pre+post flood\n",
    "\n",
    "print(\"Building Change Detection ResUNet model...\")\n",
    "try:\n",
    "    model = build_change_detection_resunet(input_shape)\n",
    "    print(\"✓ Enhanced Change Detection ResUNet model built successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Enhanced model failed: {e}\")\n",
    "    print(\"Falling back to simpler Change Detection ResUNet model...\")\n",
    "    model = build_simple_change_detection_resunet(input_shape)\n",
    "    print(\"✓ Simple Change Detection ResUNet model built successfully\")\n",
    "\n",
    "# Get optimized optimizer\n",
    "optimizer = optimizers.AdamW(\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.01,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-7,\n",
    "    clipnorm=1.0\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=optimized_focal_tversky_loss,\n",
    "    metrics=[\n",
    "        dice_coefficient,\n",
    "        iou_score,\n",
    "        'binary_accuracy',\n",
    "        f1_score_metric,\n",
    "        precision_metric,\n",
    "        recall_metric\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Get callbacks\n",
    "callbacks_list = get_optimized_callbacks(OUTPUT_PATH, EPOCHS)\n",
    "\n",
    "# Calculate steps\n",
    "steps_per_epoch = max(1, train_size // BATCH_SIZE)\n",
    "validation_steps = max(1, val_size // BATCH_SIZE)\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n",
    "\n",
    "# Train the change detection model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plot_history(history)\n",
    "\n",
    "# Load and evaluate best model\n",
    "best_iou_model_path = os.path.join(OUTPUT_PATH, \"best_iou_change_detection_model.keras\")\n",
    "\n",
    "# Custom objects dictionary with all custom functions and layers\n",
    "custom_objects_dict = {\n",
    "    'optimized_focal_tversky_loss': optimized_focal_tversky_loss,\n",
    "    'dice_coefficient': dice_coefficient,\n",
    "    'iou_score': iou_score,\n",
    "    'f1_score_metric': f1_score_metric,\n",
    "    'precision_metric': precision_metric,\n",
    "    'recall_metric': recall_metric,\n",
    "    'ChannelMean': ChannelMean,\n",
    "    'ChannelMax': ChannelMax\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Try loading with safe mode first\n",
    "    best_iou_model = models.load_model(best_iou_model_path, custom_objects=custom_objects_dict)\n",
    "    print(\"✓ Model loaded successfully with safe mode\")\n",
    "except ValueError as e:\n",
    "    if \"Lambda\" in str(e) and \"unsafe\" in str(e):\n",
    "        print(\"⚠ Model contains Lambda layers, loading with safe_mode=False...\")\n",
    "        # If the model contains Lambda layers, we need to disable safe mode\n",
    "        # This is safe in our case since we know the model architecture\n",
    "        import keras\n",
    "        keras.config.enable_unsafe_deserialization()\n",
    "        best_iou_model = models.load_model(best_iou_model_path, custom_objects=custom_objects_dict)\n",
    "        print(\"✓ Model loaded successfully with unsafe deserialization\")\n",
    "    else:\n",
    "        print(f\"✗ Failed to load model: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating best IoU model on test set...\")\n",
    "test_steps = max(1, test_size // BATCH_SIZE)\n",
    "test_results = best_iou_model.evaluate(test_dataset, steps=test_steps, verbose=1)\n",
    "print(\"\\nChange Detection Test Results:\")\n",
    "for metric_name, value in zip(best_iou_model.metrics_names, test_results):\n",
    "    print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "# Save test results\n",
    "test_metrics = {metric_name: float(value) for metric_name, value in zip(best_iou_model.metrics_names, test_results)}\n",
    "with open(os.path.join(OUTPUT_PATH, 'change_detection_test_metrics.json'), 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=4)\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_change_detection_predictions(best_iou_model, test_dataset, num_samples=5)\n",
    "\n",
    "# Calculate detailed metrics\n",
    "test_batches_for_eval = min(15, test_size // BATCH_SIZE)\n",
    "print(f\"Calculating detailed metrics on {test_batches_for_eval} test batches...\")\n",
    "detailed_metrics = calculate_metrics(best_iou_model, test_dataset, num_batches=test_batches_for_eval)\n",
    "\n",
    "# Save detailed metrics\n",
    "with open(os.path.join(OUTPUT_PATH, 'change_detection_detailed_metrics.json'), 'w') as f:\n",
    "    json.dump(detailed_metrics, f, indent=4)\n",
    "\n",
    "# Save final model\n",
    "best_iou_model.save(os.path.join(OUTPUT_PATH, 'final_change_detection_flood_model.keras'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CHANGE DETECTION TRAINING COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(\"Key Features:\")\n",
    "print(\"✓ 6-channel input (pre-flood + post-flood images)\")\n",
    "print(\"✓ Enhanced ResUNet architecture for change detection\")\n",
    "print(\"✓ Optimized for flood detection from temporal image pairs\")\n",
    "print(\"✓ Comprehensive evaluation metrics\")\n",
    "print(\"✓ Robust data augmentation for change detection\")\n",
    "print(\"=\"*50)\n",
    "print(f\"All outputs saved to: {OUTPUT_PATH}\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
