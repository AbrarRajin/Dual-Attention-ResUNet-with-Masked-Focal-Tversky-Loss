{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoJBw0lAglqi",
        "outputId": "8b23d51f-c687-42f5-afd7-fd402bead8fa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/facebookresearch/sam2.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYF2iDK-hzUD",
        "outputId": "1ca50219-db12-4b6e-e32c-8505cd4d971b"
      },
      "outputs": [],
      "source": [
        "cd sam2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRdAg4Z6h-76",
        "outputId": "aae3b172-fdd3-4b45-c2cd-68c45dad5c97"
      },
      "outputs": [],
      "source": [
        "!pip install setuptools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6ZI69HulF02",
        "outputId": "9e67fd98-d84a-4749-c2eb-74416bee9e02"
      },
      "outputs": [],
      "source": [
        "!pip install -e /content/sam2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3KgSMoKi-S4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/sam2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPdYajSNglsx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.utils\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(3)\n",
        "torch.manual_seed(3)\n",
        "random.seed(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ShjY15pglvJ",
        "outputId": "4fb72926-002f-4e45-df33-a509a14a9db5"
      },
      "outputs": [],
      "source": [
        "# Define consistent paths\n",
        "ROOT_PATH = \"/content/drive/MyDrive/preprocessed/train/\"\n",
        "IMAGES_DIR = os.path.join(ROOT_PATH, \"images/rgb/\")\n",
        "MASKS_DIR = os.path.join(ROOT_PATH, \"masks/\")\n",
        "CHECKPOINT_DIR = \"./checkpoints/\"\n",
        "FINE_TUNED_MODEL_DIR = \"./\"\n",
        "\n",
        "# Create DataFrame containing image and mask paths\n",
        "image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.endswith(\".png\")])\n",
        "mask_files = sorted([f for f in os.listdir(MASKS_DIR) if f.endswith(\".png\")])\n",
        "\n",
        "data_df = pd.DataFrame({\n",
        "    \"ImageId\": image_files,\n",
        "    \"MaskId\": mask_files,\n",
        "    \"image_path\": [os.path.join(IMAGES_DIR, img) for img in image_files],\n",
        "    \"mask_path\": [os.path.join(MASKS_DIR, mask) for mask in mask_files]\n",
        "})\n",
        "\n",
        "# Split data into train and validation sets\n",
        "train_df, val_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare data lists\n",
        "train_data = [\n",
        "    {\"image\": row['image_path'], \"annotation\": row['mask_path']}\n",
        "    for _, row in train_df.iterrows()\n",
        "]\n",
        "\n",
        "val_data = [\n",
        "    {\"image\": row['image_path'], \"annotation\": row['mask_path']}\n",
        "    for _, row in val_df.iterrows()\n",
        "]\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agvtvs7vglxq"
      },
      "outputs": [],
      "source": [
        "# Function to visualize segmentation masks\n",
        "def show_anns(anns, borders=True):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "\n",
        "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "    img[:, :, 3] = 0\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        color_mask = np.concatenate([np.random.random(3), [1]])\n",
        "        img[m] = color_mask\n",
        "        if borders:\n",
        "            import cv2\n",
        "            contours, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "            # Try to smooth contours\n",
        "            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
        "            cv2.drawContours(img, contours, -1, (0, 0, 1, 0.4), thickness=1)\n",
        "\n",
        "    ax.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHGypMLdgru3"
      },
      "outputs": [],
      "source": [
        "# Improved read_batch function\n",
        "def read_batch(data, visualize_data=False):\n",
        "    # Select a random entry\n",
        "    ent = data[np.random.randint(len(data))]\n",
        "\n",
        "    # Get full paths\n",
        "    img = cv2.imread(ent[\"image\"])[..., ::-1]  # Convert BGR to RGB\n",
        "    ann_map = cv2.imread(ent[\"annotation\"], cv2.IMREAD_GRAYSCALE)  # Read annotation as grayscale\n",
        "\n",
        "    if img is None or ann_map is None:\n",
        "        print(f\"Error: Could not read image or mask from path {ent['image']} or {ent['annotation']}\")\n",
        "        return None, None, None, 0\n",
        "\n",
        "    # Resize image and mask\n",
        "    r = np.min([1024 / img.shape[1], 1024 / img.shape[0]])  # Scaling factor\n",
        "    img = cv2.resize(img, (int(img.shape[1] * r), int(img.shape[0] * r)))\n",
        "    ann_map = cv2.resize(ann_map, (int(ann_map.shape[1] * r), int(ann_map.shape[0] * r)),\n",
        "                         interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # Initialize a single binary mask\n",
        "    binary_mask = np.zeros_like(ann_map, dtype=np.uint8)\n",
        "    points = []\n",
        "\n",
        "    # Get binary masks and combine them into a single mask\n",
        "    inds = np.unique(ann_map)[1:]  # Skip the background (index 0)\n",
        "    if len(inds) == 0:  # Handle case with no segmentation\n",
        "        return None, None, None, 0\n",
        "\n",
        "    for ind in inds:\n",
        "        mask = (ann_map == ind).astype(np.uint8)  # Create binary mask for each unique index\n",
        "        binary_mask = np.maximum(binary_mask, mask)  # Combine with the existing binary mask\n",
        "\n",
        "    # Erode the combined binary mask to avoid boundary points\n",
        "    eroded_mask = cv2.erode(binary_mask, np.ones((5, 5), np.uint8), iterations=1)\n",
        "\n",
        "    # Get all coordinates inside the eroded mask and choose random points\n",
        "    coords = np.argwhere(eroded_mask > 0)\n",
        "    if len(coords) > 0:\n",
        "        for _ in inds:  # Select as many points as there are unique labels\n",
        "            yx = np.array(coords[np.random.randint(len(coords))])\n",
        "            points.append([yx[1], yx[0]])\n",
        "\n",
        "    points = np.array(points)\n",
        "    if len(points) == 0:  # Handle case with no valid points\n",
        "        return None, None, None, 0\n",
        "\n",
        "    if visualize_data:\n",
        "        # Plotting the images and points\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Original Image\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title('Original Image')\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Segmentation Mask (binary_mask)\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title('Binarized Mask')\n",
        "        plt.imshow(binary_mask, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Mask with Points in Different Colors\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title('Binarized Mask with Points')\n",
        "        plt.imshow(binary_mask, cmap='gray')\n",
        "\n",
        "        # Plot points in different colors\n",
        "        colors = list(mcolors.TABLEAU_COLORS.values())\n",
        "        for i, point in enumerate(points):\n",
        "            plt.scatter(point[0], point[1], c=colors[i % len(colors)], s=100, label=f'Point {i+1}')\n",
        "\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    binary_mask = np.expand_dims(binary_mask, axis=-1)  # Now shape is (H, W, 1)\n",
        "    binary_mask = binary_mask.transpose((2, 0, 1))\n",
        "    points = np.expand_dims(points, axis=1)\n",
        "\n",
        "    # Return the image, binarized mask, points, and number of masks\n",
        "    return img, binary_mask, points, len(inds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SoCzrQ9grx6"
      },
      "outputs": [],
      "source": [
        "# Evaluation function to compute validation metrics\n",
        "def evaluate_model(predictor, data, num_samples=50):\n",
        "    total_iou = 0\n",
        "    total_loss = 0\n",
        "    valid_samples = 0\n",
        "\n",
        "    for i in range(min(num_samples, len(data))):\n",
        "        with torch.no_grad():\n",
        "            image, mask, input_point, num_masks = read_batch([data[i]], visualize_data=False)\n",
        "            if image is None or mask is None or num_masks == 0:\n",
        "                continue\n",
        "\n",
        "            input_label = np.ones((num_masks, 1))\n",
        "            if not isinstance(input_point, np.ndarray) or not isinstance(input_label, np.ndarray):\n",
        "                continue\n",
        "\n",
        "            if input_point.size == 0 or input_label.size == 0:\n",
        "                continue\n",
        "\n",
        "            # Set image and get predictions\n",
        "            predictor.set_image(image)\n",
        "            mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n",
        "                input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n",
        "            )\n",
        "\n",
        "            if unnorm_coords is None or labels is None or unnorm_coords.shape[0] == 0 or labels.shape[0] == 0:\n",
        "                continue\n",
        "\n",
        "            sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
        "                points=(unnorm_coords, labels), boxes=None, masks=None,\n",
        "            )\n",
        "\n",
        "            batched_mode = unnorm_coords.shape[0] > 1\n",
        "            high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
        "            low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
        "                image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n",
        "                image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
        "                sparse_prompt_embeddings=sparse_embeddings,\n",
        "                dense_prompt_embeddings=dense_embeddings,\n",
        "                multimask_output=True,\n",
        "                repeat_image=batched_mode,\n",
        "                high_res_features=high_res_features,\n",
        "            )\n",
        "            prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
        "\n",
        "            # Convert to tensors\n",
        "            gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
        "            prd_mask = torch.sigmoid(prd_masks[:, 0])\n",
        "\n",
        "            # Calculate loss\n",
        "            seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6) - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n",
        "\n",
        "            # Calculate IoU\n",
        "            inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n",
        "            union = gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter\n",
        "            iou = inter / (union + 1e-6)\n",
        "\n",
        "            score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
        "            loss = seg_loss + score_loss * 0.05\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_iou += iou.mean().item()\n",
        "            valid_samples += 1\n",
        "\n",
        "    if valid_samples == 0:\n",
        "        return 0, 0\n",
        "\n",
        "    return total_loss / valid_samples, total_iou / valid_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Je_uc8-qgr1L"
      },
      "outputs": [],
      "source": [
        "# Evaluation function to compute validation metrics\n",
        "def evaluate_model(predictor, data, num_samples=50):\n",
        "    total_iou = 0\n",
        "    total_loss = 0\n",
        "    valid_samples = 0\n",
        "\n",
        "    for i in range(min(num_samples, len(data))):\n",
        "        with torch.no_grad():\n",
        "            image, mask, input_point, num_masks = read_batch([data[i]], visualize_data=False)\n",
        "            if image is None or mask is None or num_masks == 0:\n",
        "                continue\n",
        "\n",
        "            input_label = np.ones((num_masks, 1))\n",
        "            if not isinstance(input_point, np.ndarray) or not isinstance(input_label, np.ndarray):\n",
        "                continue\n",
        "\n",
        "            if input_point.size == 0 or input_label.size == 0:\n",
        "                continue\n",
        "\n",
        "            # Set image and get predictions\n",
        "            predictor.set_image(image)\n",
        "            mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n",
        "                input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n",
        "            )\n",
        "\n",
        "            if unnorm_coords is None or labels is None or unnorm_coords.shape[0] == 0 or labels.shape[0] == 0:\n",
        "                continue\n",
        "\n",
        "            sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
        "                points=(unnorm_coords, labels), boxes=None, masks=None,\n",
        "            )\n",
        "\n",
        "            batched_mode = unnorm_coords.shape[0] > 1\n",
        "            high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
        "            low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
        "                image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n",
        "                image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
        "                sparse_prompt_embeddings=sparse_embeddings,\n",
        "                dense_prompt_embeddings=dense_embeddings,\n",
        "                multimask_output=True,\n",
        "                repeat_image=batched_mode,\n",
        "                high_res_features=high_res_features,\n",
        "            )\n",
        "            prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
        "\n",
        "            # Convert to tensors\n",
        "            gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
        "            prd_mask = torch.sigmoid(prd_masks[:, 0])\n",
        "\n",
        "            # Calculate loss\n",
        "            seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6) - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n",
        "\n",
        "            # Calculate IoU\n",
        "            inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n",
        "            union = gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter\n",
        "            iou = inter / (union + 1e-6)\n",
        "\n",
        "            score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
        "            loss = seg_loss + score_loss * 0.05\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_iou += iou.mean().item()\n",
        "            valid_samples += 1\n",
        "\n",
        "    if valid_samples == 0:\n",
        "        return 0, 0\n",
        "\n",
        "    return total_loss / valid_samples, total_iou / valid_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR6KHKsQrzq8"
      },
      "outputs": [],
      "source": [
        "# Add accuracy calculation to the evaluation function\n",
        "def evaluate_model(predictor, data, num_samples=50):\n",
        "    total_iou = 0\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    valid_samples = 0\n",
        "\n",
        "    for i in range(min(num_samples, len(data))):\n",
        "        with torch.no_grad():\n",
        "            image, mask, input_point, num_masks = read_batch([data[i]], visualize_data=False)\n",
        "            if image is None or mask is None or num_masks == 0:\n",
        "                continue\n",
        "\n",
        "            input_label = np.ones((num_masks, 1))\n",
        "            if not isinstance(input_point, np.ndarray) or not isinstance(input_label, np.ndarray):\n",
        "                continue\n",
        "\n",
        "            if input_point.size == 0 or input_label.size == 0:\n",
        "                continue\n",
        "\n",
        "            # Set image and get predictions\n",
        "            predictor.set_image(image)\n",
        "            mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n",
        "                input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n",
        "            )\n",
        "\n",
        "            if unnorm_coords is None or labels is None or unnorm_coords.shape[0] == 0 or labels.shape[0] == 0:\n",
        "                continue\n",
        "\n",
        "            sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
        "                points=(unnorm_coords, labels), boxes=None, masks=None,\n",
        "            )\n",
        "\n",
        "            batched_mode = unnorm_coords.shape[0] > 1\n",
        "            high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
        "            low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
        "                image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n",
        "                image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
        "                sparse_prompt_embeddings=sparse_embeddings,\n",
        "                dense_prompt_embeddings=dense_embeddings,\n",
        "                multimask_output=True,\n",
        "                repeat_image=batched_mode,\n",
        "                high_res_features=high_res_features,\n",
        "            )\n",
        "            prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
        "\n",
        "            # Convert to tensors\n",
        "            gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
        "            prd_mask = torch.sigmoid(prd_masks[:, 0])\n",
        "\n",
        "            # Calculate binary prediction (0 or 1)\n",
        "            pred_binary = (prd_mask > 0.5).float()\n",
        "\n",
        "            # Calculate loss\n",
        "            seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6) - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n",
        "\n",
        "            # Calculate IoU\n",
        "            inter = (gt_mask * pred_binary).sum(1).sum(1)\n",
        "            union = gt_mask.sum(1).sum(1) + pred_binary.sum(1).sum(1) - inter\n",
        "            iou = inter / (union + 1e-6)\n",
        "\n",
        "            # Calculate pixel accuracy\n",
        "            total_pixels = gt_mask.numel()\n",
        "            correct_pixels = ((pred_binary == gt_mask).float()).sum()\n",
        "            accuracy = correct_pixels / total_pixels\n",
        "\n",
        "            score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
        "            loss = seg_loss + score_loss * 0.05\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_iou += iou.mean().item()\n",
        "            total_accuracy += accuracy.item()\n",
        "            valid_samples += 1\n",
        "\n",
        "    if valid_samples == 0:\n",
        "        return 0, 0, 0\n",
        "\n",
        "    return total_loss / valid_samples, total_iou / valid_samples, total_accuracy / valid_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaqXt0Akgy4Q",
        "outputId": "14e0df99-d71b-4826-b5ed-5366aa455982"
      },
      "outputs": [],
      "source": [
        "# Download and setup the SAM2 model\n",
        "!wget -O sam2.1_hiera_large.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\"\n",
        "!mkdir -p checkpoints\n",
        "!mv sam2.1_hiera_large.pt checkpoints/\n",
        "\n",
        "# Model configuration\n",
        "sam2_checkpoint = \"./checkpoints/sam2.1_hiera_large.pt\"\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Build the model for finetuning\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device)\n",
        "predictor = SAM2ImagePredictor(sam2_model)\n",
        "\n",
        "# Set model to training mode\n",
        "predictor.model.sam_mask_decoder.train(True)\n",
        "predictor.model.sam_prompt_encoder.train(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abIvxW-wglzo",
        "outputId": "1b95a399-8a0c-4302-8640-5bd0dcd41f93"
      },
      "outputs": [],
      "source": [
        "# Configure optimizer and other training parameters\n",
        "optimizer = torch.optim.AdamW(params=predictor.model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.2)\n",
        "NO_OF_STEPS = 6000\n",
        "accumulation_steps = 4\n",
        "FINE_TUNED_MODEL_NAME = \"fine_tuned_sam2\"\n",
        "\n",
        "# Initialize metrics tracking\n",
        "train_losses = []\n",
        "train_ious = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_ious = []\n",
        "val_accuracies = []\n",
        "best_val_iou = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUmbFJmCgl11",
        "outputId": "df7350f1-f736-4b59-b754-99ba344acb3f"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "for step in range(1, NO_OF_STEPS + 1):\n",
        "    with torch.cuda.amp.autocast():\n",
        "        image, mask, input_point, num_masks = read_batch(train_data, visualize_data=False)\n",
        "        if image is None or mask is None or num_masks == 0:\n",
        "            continue\n",
        "\n",
        "        input_label = np.ones((num_masks, 1))\n",
        "        if not isinstance(input_point, np.ndarray) or not isinstance(input_label, np.ndarray):\n",
        "            continue\n",
        "\n",
        "        if input_point.size == 0 or input_label.size == 0:\n",
        "            continue\n",
        "\n",
        "        predictor.set_image(image)\n",
        "        mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(input_point, input_label, box=None, mask_logits=None, normalize_coords=True)\n",
        "        if unnorm_coords is None or labels is None or unnorm_coords.shape[0] == 0 or labels.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "        sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
        "            points=(unnorm_coords, labels), boxes=None, masks=None,\n",
        "        )\n",
        "\n",
        "        batched_mode = unnorm_coords.shape[0] > 1\n",
        "        high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
        "        low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
        "            image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n",
        "            image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
        "            sparse_prompt_embeddings=sparse_embeddings,\n",
        "            dense_prompt_embeddings=dense_embeddings,\n",
        "            multimask_output=True,\n",
        "            repeat_image=batched_mode,\n",
        "            high_res_features=high_res_features,\n",
        "        )\n",
        "        prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
        "\n",
        "        gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
        "        prd_mask = torch.sigmoid(prd_masks[:, 0])\n",
        "\n",
        "        # Calculate binary prediction (0 or 1)\n",
        "        pred_binary = (prd_mask > 0.5).float()\n",
        "\n",
        "        # Calculate pixel accuracy\n",
        "        total_pixels = gt_mask.numel()\n",
        "        correct_pixels = ((pred_binary == gt_mask).float()).sum()\n",
        "        accuracy = correct_pixels / total_pixels\n",
        "\n",
        "        seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6) - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n",
        "\n",
        "        inter = (gt_mask * pred_binary).sum(1).sum(1)\n",
        "        union = gt_mask.sum(1).sum(1) + pred_binary.sum(1).sum(1) - inter\n",
        "        iou = inter / (union + 1e-6)\n",
        "        score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
        "        loss = seg_loss + score_loss * 0.05\n",
        "\n",
        "        # Apply gradient accumulation\n",
        "        loss = loss / accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Track training metrics\n",
        "        if step == 1:\n",
        "            mean_iou = iou.mean().item()\n",
        "            mean_loss = loss.item() * accumulation_steps\n",
        "            mean_accuracy = accuracy.item()\n",
        "        else:\n",
        "            mean_iou = mean_iou * 0.95 + 0.05 * iou.mean().item()\n",
        "            mean_loss = mean_loss * 0.95 + 0.05 * (loss.item() * accumulation_steps)\n",
        "            mean_accuracy = mean_accuracy * 0.95 + 0.05 * accuracy.item()\n",
        "\n",
        "        # Update weights after accumulation steps\n",
        "        if step % accumulation_steps == 0:\n",
        "            # Clip gradients\n",
        "            torch.nn.utils.clip_grad_norm_(predictor.model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluate on validation set periodically\n",
        "        if step % 500 == 0 or step == NO_OF_STEPS:\n",
        "            # Save model checkpoint\n",
        "            FINE_TUNED_MODEL = f\"{FINE_TUNED_MODEL_NAME}_{step}.torch\"\n",
        "            torch.save(predictor.model.state_dict(), FINE_TUNED_MODEL)\n",
        "\n",
        "            # Temporarily set model to eval mode\n",
        "            predictor.model.eval()\n",
        "            val_loss, val_iou, val_accuracy = evaluate_model(predictor, val_data)\n",
        "            predictor.model.train()\n",
        "\n",
        "            # Track metrics\n",
        "            train_losses.append(mean_loss)\n",
        "            train_ious.append(mean_iou)\n",
        "            train_accuracies.append(mean_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "            val_ious.append(val_iou)\n",
        "            val_accuracies.append(val_accuracy)\n",
        "\n",
        "            # Save best model\n",
        "            if val_iou > best_val_iou:\n",
        "                best_val_iou = val_iou\n",
        "                torch.save(predictor.model.state_dict(), f\"{FINE_TUNED_MODEL_NAME}_best.torch\")\n",
        "\n",
        "            print(f\"Step {step}:\")\n",
        "            print(f\"  Train Loss: {mean_loss:.4f}, Train IoU: {mean_iou:.4f}, Train Accuracy: {mean_accuracy:.4f}\")\n",
        "            print(f\"  Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Display progress more frequently\n",
        "        elif step % 100 == 0:\n",
        "            print(f\"Step {step}: Train Loss: {mean_loss:.4f}, Train IoU: {mean_iou:.4f}, Train Accuracy: {mean_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjpqPR49gl4J",
        "outputId": "26176c4b-7a8b-483e-e3a7-c17d0b35c7ea"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot([500 * (i+1) for i in range(len(train_losses))], train_losses, label='Train Loss')\n",
        "plt.plot([500 * (i+1) for i in range(len(val_losses))], val_losses, label='Val Loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot([500 * (i+1) for i in range(len(train_ious))], train_ious, label='Train IoU')\n",
        "plt.plot([500 * (i+1) for i in range(len(val_ious))], val_ious, label='Val IoU')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('IoU')\n",
        "plt.title('Training and Validation IoU')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot([500 * (i+1) for i in range(len(train_accuracies))], train_accuracies, label='Train Accuracy')\n",
        "plt.plot([500 * (i+1) for i in range(len(val_accuracies))], val_accuracies, label='Val Accuracy')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Pixel Accuracy')\n",
        "plt.title('Training and Validation Pixel Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_metrics_with_accuracy.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBw3HuT2hAFM",
        "outputId": "0dfdcc92-ca29-4b23-b6b8-fe4fcd601dfd"
      },
      "outputs": [],
      "source": [
        "# Load the best model for inference\n",
        "best_model_weights = f\"{FINE_TUNED_MODEL_NAME}_best.torch\"\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
        "predictor = SAM2ImagePredictor(sam2_model)\n",
        "predictor.model.load_state_dict(torch.load(best_model_weights))\n",
        "predictor.model.eval()\n",
        "\n",
        "# Test inference on a random validation sample\n",
        "def read_image(image_path, mask_path):  # read and resize image and mask\n",
        "    img = cv2.imread(image_path)[..., ::-1]  # Convert BGR to RGB\n",
        "    mask = cv2.imread(mask_path, 0)\n",
        "\n",
        "    # Check if image or mask is None\n",
        "    if img is None or mask is None:\n",
        "        print(f\"Warning: Could not read image from {image_path} or mask from {mask_path}\")\n",
        "        return None, None\n",
        "\n",
        "    r = np.min([1024 / img.shape[1], 1024 / img.shape[0]])\n",
        "    img = cv2.resize(img, (int(img.shape[1] * r), int(img.shape[0] * r)))\n",
        "    mask = cv2.resize(mask, (int(mask.shape[1] * r), int(mask.shape[0] * r)), interpolation=cv2.INTER_NEAREST)\n",
        "    return img, mask\n",
        "\n",
        "def get_points(mask, num_points):  # Sample points inside the input mask\n",
        "    # Check if mask is empty\n",
        "    if mask is None:\n",
        "        return np.array([])\n",
        "\n",
        "    # Make sure we have foreground pixels\n",
        "    if np.max(mask) == 0:\n",
        "        print(\"Warning: Mask is empty (all zeros)\")\n",
        "        return np.array([])\n",
        "\n",
        "    # Get coordinates of foreground pixels\n",
        "    coords = np.argwhere(mask > 0)\n",
        "    if len(coords) == 0:\n",
        "        return np.array([])\n",
        "\n",
        "    # Sample random points\n",
        "    points = []\n",
        "    for i in range(min(num_points, len(coords))):\n",
        "        yx = np.array(coords[np.random.randint(len(coords))])\n",
        "        points.append([[yx[1], yx[0]]])\n",
        "    return np.array(points)\n",
        "\n",
        "# Try multiple validation images until we find one with valid points\n",
        "max_attempts = 10\n",
        "attempt = 0\n",
        "found_valid_image = False\n",
        "\n",
        "while attempt < max_attempts and not found_valid_image:\n",
        "    # Randomly select a test image from the validation data\n",
        "    selected_entry = random.choice(val_data)\n",
        "    image_path = selected_entry['image']\n",
        "    mask_path = selected_entry['annotation']\n",
        "\n",
        "    print(f\"Attempt {attempt+1}: Trying image {os.path.basename(image_path)}\")\n",
        "\n",
        "    # Load the selected image and mask\n",
        "    image, mask = read_image(image_path, mask_path)\n",
        "\n",
        "    # Check if image and mask were loaded successfully\n",
        "    if image is None or mask is None:\n",
        "        attempt += 1\n",
        "        continue\n",
        "\n",
        "    # Check if mask contains any foreground pixels\n",
        "    if np.max(mask) == 0:\n",
        "        print(f\"Mask for {os.path.basename(image_path)} is empty. Trying another image.\")\n",
        "        attempt += 1\n",
        "        continue\n",
        "\n",
        "    # Generate random points for the input\n",
        "    num_samples = 30  # Number of points per segment to sample\n",
        "    input_points = get_points(mask, num_samples)\n",
        "\n",
        "    if len(input_points) > 0:\n",
        "        found_valid_image = True\n",
        "        print(f\"Found valid image: {os.path.basename(image_path)}\")\n",
        "    else:\n",
        "        print(f\"No valid points found in {os.path.basename(image_path)}. Trying another image.\")\n",
        "        attempt += 1\n",
        "\n",
        "if not found_valid_image:\n",
        "    print(f\"Failed to find a valid image after {max_attempts} attempts.\")\n",
        "    print(\"Please check your validation dataset or increase the number of attempts.\")\n",
        "else:\n",
        "    # Perform inference and predict masks\n",
        "    with torch.no_grad():\n",
        "        predictor.set_image(image)\n",
        "        masks, scores, logits = predictor.predict(\n",
        "            point_coords=input_points,\n",
        "            point_labels=np.ones([input_points.shape[0], 1])\n",
        "        )\n",
        "\n",
        "    # Process the predicted masks and sort by scores\n",
        "    np_masks = np.array(masks[:, 0])\n",
        "    np_scores = scores[:, 0]\n",
        "    sorted_indices = np.argsort(np_scores)[::-1]\n",
        "    sorted_masks = np_masks[sorted_indices]\n",
        "    sorted_scores = np_scores[sorted_indices]  # Also keep track of sorted scores\n",
        "\n",
        "    # Print score information\n",
        "    print(f\"Number of predicted masks: {len(sorted_scores)}\")\n",
        "    print(f\"Prediction scores (top 5): {sorted_scores[:5]}\")\n",
        "\n",
        "    # Initialize segmentation map and occupancy mask\n",
        "    seg_map = np.zeros_like(sorted_masks[0], dtype=np.uint8)\n",
        "    occupancy_mask = np.zeros_like(sorted_masks[0], dtype=bool)\n",
        "\n",
        "    # Combine masks to create the final segmentation map\n",
        "    for i in range(sorted_masks.shape[0]):\n",
        "        mask_i = sorted_masks[i]\n",
        "\n",
        "        # Skip masks with low scores\n",
        "        if sorted_scores[i] < 0.7:  # You can adjust this threshold\n",
        "            continue\n",
        "\n",
        "        # Calculate overlap with existing mask\n",
        "        overlap_ratio = 0\n",
        "        if mask_i.sum() > 0:  # Avoid division by zero\n",
        "            overlap_ratio = (mask_i * occupancy_mask).sum() / mask_i.sum()\n",
        "\n",
        "        # Skip if there's too much overlap\n",
        "        if overlap_ratio > 0.15:\n",
        "            continue\n",
        "\n",
        "        mask_bool = mask_i.astype(bool)\n",
        "        mask_bool[occupancy_mask] = False  # Set overlapping areas to False in the mask\n",
        "        seg_map[mask_bool] = i + 1  # Use boolean mask to index seg_map\n",
        "        occupancy_mask[mask_bool] = True  # Update occupancy_mask\n",
        "\n",
        "    # Visualization: Show the original image, mask, input points, and final segmentation\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.title('Test Image')\n",
        "    plt.imshow(image)\n",
        "    # Plot points on the image\n",
        "    for point in input_points:\n",
        "        plt.scatter(point[0][0], point[0][1], c='r', s=40)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.title('Original Mask')\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.title('Highest Scoring Predicted Mask')\n",
        "    # Show the highest-scoring mask\n",
        "    if len(sorted_masks) > 0:\n",
        "        plt.imshow(sorted_masks[0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.title('Final Segmentation')\n",
        "    plt.imshow(seg_map, cmap='jet')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('inference_example.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate metrics for the inference result\n",
        "    gt_binary = mask > 0  # Convert ground truth mask to binary\n",
        "    pred_binary = seg_map > 0  # Convert prediction to binary\n",
        "\n",
        "    # Calculate IoU\n",
        "    intersection = np.logical_and(gt_binary, pred_binary).sum()\n",
        "    union = np.logical_or(gt_binary, pred_binary).sum()\n",
        "    iou = intersection / union if union > 0 else 0\n",
        "\n",
        "    # Calculate pixel accuracy\n",
        "    total_pixels = gt_binary.size\n",
        "    correct_pixels = np.sum(gt_binary == pred_binary)\n",
        "    accuracy = correct_pixels / total_pixels\n",
        "\n",
        "    print(f\"Inference metrics - IoU: {iou:.4f}, Pixel Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3cRJMQ2uC2i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
