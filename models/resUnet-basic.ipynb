{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pSQMOUt8J39",
        "outputId": "8dedc1de-df3b-4d15-8cf2-fb3b6361e5a2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOypI_xT2pZC",
        "outputId": "2cf4447e-9e4b-4fbe-c9b1-cb94f41349a8"
      },
      "outputs": [],
      "source": [
        "# CELL 1: Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "import random\n",
        "import glob\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
        "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5eRzPGC2ukD"
      },
      "outputs": [],
      "source": [
        "# CELL 2: Define helper functions for data loading\n",
        "def load_image(image_path):\n",
        "    \"\"\"Load normalized image data from .npy file\"\"\"\n",
        "    # Convert tensor to string if needed\n",
        "    if isinstance(image_path, tf.Tensor):\n",
        "        image_path = image_path.numpy().decode('utf-8')\n",
        "    # Explicitly convert to float32\n",
        "    return np.load(image_path).astype(np.float32)\n",
        "\n",
        "def load_mask(mask_path):\n",
        "    \"\"\"Load mask from PNG file\"\"\"\n",
        "    # Convert tensor to string if needed\n",
        "    if isinstance(mask_path, tf.Tensor):\n",
        "        mask_path = mask_path.numpy().decode('utf-8')\n",
        "    mask = plt.imread(mask_path)\n",
        "    # Convert to binary mask if needed\n",
        "    if len(mask.shape) > 2 and mask.shape[2] > 1:\n",
        "        mask = mask[:, :, 0]\n",
        "    # Explicitly convert to float32\n",
        "    return (mask > 0).astype(np.float32)\n",
        "\n",
        "def create_dataset(base_path, split, batch_size=8, shuffle=True):\n",
        "    \"\"\"Create a TensorFlow dataset for the specified split\"\"\"\n",
        "    img_paths = sorted(glob.glob(os.path.join(base_path, split, 'images', '*.npy')))\n",
        "    # If no .npy files, try .png files\n",
        "    if len(img_paths) == 0:\n",
        "        img_paths = sorted(glob.glob(os.path.join(base_path, split, 'images', '*.png')))\n",
        "        print(f\"Using PNG files for images in {split} split\")\n",
        "\n",
        "    mask_paths = sorted(glob.glob(os.path.join(base_path, split, 'masks', '*.png')))\n",
        "\n",
        "    if len(img_paths) == 0 or len(mask_paths) == 0:\n",
        "        raise ValueError(f\"No images or masks found in {base_path}/{split}\")\n",
        "\n",
        "    print(f\"Found {len(img_paths)} images and {len(mask_paths)} masks for {split}\")\n",
        "\n",
        "    # Create a dataset of image paths\n",
        "    img_dataset = tf.data.Dataset.from_tensor_slices(img_paths)\n",
        "    mask_dataset = tf.data.Dataset.from_tensor_slices(mask_paths)\n",
        "\n",
        "    # Combine image and mask paths\n",
        "    dataset = tf.data.Dataset.zip((img_dataset, mask_dataset))\n",
        "\n",
        "    # Shuffle if needed\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(img_paths), seed=42)\n",
        "\n",
        "    # Map loading function to the dataset\n",
        "    dataset = dataset.map(\n",
        "        lambda img_path, mask_path: (\n",
        "            tf.py_function(\n",
        "                func=load_image,\n",
        "                inp=[img_path],\n",
        "                Tout=tf.float32\n",
        "            ),\n",
        "            tf.py_function(\n",
        "                func=load_mask,\n",
        "                inp=[mask_path],\n",
        "                Tout=tf.float32\n",
        "            )\n",
        "        ),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    # Set shapes\n",
        "    dataset = dataset.map(\n",
        "        lambda x, y: (\n",
        "            tf.ensure_shape(x, [256, 256, 3]),\n",
        "            tf.ensure_shape(y, [256, 256])\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Add channel dimension to mask\n",
        "    dataset = dataset.map(lambda x, y: (x, tf.expand_dims(y, axis=-1)))\n",
        "\n",
        "    # Batch and prefetch\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_accuracy(history):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot training and validation binary accuracy\n",
        "    plt.plot(history.history['binary_accuracy'], label='Training Binary Accuracy')\n",
        "    plt.plot(history.history['val_binary_accuracy'], label='Validation Binary Accuracy')\n",
        "\n",
        "    # Plot training and validation general accuracy (if available)\n",
        "    if 'accuracy' in history.history and 'val_accuracy' in history.history:\n",
        "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_samples(dataset, num_samples=3):\n",
        "    \"\"\"Visualize random samples from the dataset\"\"\"\n",
        "    plt.figure(figsize=(15, 5*num_samples))\n",
        "\n",
        "    for i, (images, masks) in enumerate(dataset.take(num_samples)):\n",
        "        for j in range(min(images.shape[0], 3)):\n",
        "            # Get image and mask\n",
        "            image = images[j].numpy()\n",
        "            mask = masks[j].numpy().squeeze()\n",
        "\n",
        "            # Normalize image for visualization (0-1 range)\n",
        "            image_viz = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
        "\n",
        "            # Display RGB channels\n",
        "            plt.subplot(num_samples, 4, i*4+1)\n",
        "            plt.imshow(image_viz[:, :, 0], cmap='gray')\n",
        "            plt.title(f\"VH Channel - Sample {i+1}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(num_samples, 4, i*4+2)\n",
        "            plt.imshow(image_viz[:, :, 1], cmap='gray')\n",
        "            plt.title(f\"VV Channel - Sample {i+1}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(num_samples, 4, i*4+3)\n",
        "            plt.imshow(image_viz[:, :, 2], cmap='gray')\n",
        "            plt.title(f\"VH/VV Ratio - Sample {i+1}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Display mask\n",
        "            plt.subplot(num_samples, 4, i*4+4)\n",
        "            plt.imshow(mask, cmap='Blues')\n",
        "            plt.title(f\"Flood Mask - Sample {i+1}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHNE8mPH2umZ"
      },
      "outputs": [],
      "source": [
        "# CELL 3: Define custom metrics and loss functions\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    \"\"\"Calculate Dice coefficient\n",
        "\n",
        "    Args:\n",
        "        y_true: Ground truth masks\n",
        "        y_pred: Predicted masks\n",
        "        smooth: Smoothing factor to avoid division by zero\n",
        "\n",
        "    Returns:\n",
        "        Dice coefficient (0-1)\n",
        "    \"\"\"\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    \"\"\"Dice loss function based on dice coefficient\"\"\"\n",
        "    return 1 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    \"\"\"Combined binary cross-entropy and dice loss\"\"\"\n",
        "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
        "    dice = dice_loss(y_true, y_pred)\n",
        "    return bce + dice\n",
        "\n",
        "def iou_score(y_true, y_pred, smooth=1e-6):\n",
        "    \"\"\"Calculate IoU (Intersection over Union) score\n",
        "\n",
        "    Args:\n",
        "        y_true: Ground truth masks\n",
        "        y_pred: Predicted masks\n",
        "        smooth: Smoothing factor to avoid division by zero\n",
        "\n",
        "    Returns:\n",
        "        IoU score (0-1)\n",
        "    \"\"\"\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "def f1_score_metric(y_true, y_pred, smooth=1e-6):\n",
        "    \"\"\"Calculate F1 score metric\n",
        "\n",
        "    Args:\n",
        "        y_true: Ground truth masks\n",
        "        y_pred: Predicted masks\n",
        "        smooth: Smoothing factor to avoid division by zero\n",
        "\n",
        "    Returns:\n",
        "        F1 score (0-1)\n",
        "    \"\"\"\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    # Calculate precision and recall\n",
        "    true_positives = K.sum(y_true_f * y_pred_f)\n",
        "    predicted_positives = K.sum(y_pred_f)\n",
        "    actual_positives = K.sum(y_true_f)\n",
        "\n",
        "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
        "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + smooth)\n",
        "    return f1\n",
        "\n",
        "def precision_metric(y_true, y_pred, smooth=1e-6):\n",
        "    \"\"\"Calculate precision metric\n",
        "\n",
        "    Args:\n",
        "        y_true: Ground truth masks\n",
        "        y_pred: Predicted masks\n",
        "        smooth: Smoothing factor to avoid division by zero\n",
        "\n",
        "    Returns:\n",
        "        Precision (0-1)\n",
        "    \"\"\"\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    true_positives = K.sum(y_true_f * y_pred_f)\n",
        "    predicted_positives = K.sum(y_pred_f)\n",
        "\n",
        "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
        "    return precision\n",
        "\n",
        "def recall_metric(y_true, y_pred, smooth=1e-6):\n",
        "    \"\"\"Calculate recall metric\n",
        "\n",
        "    Args:\n",
        "        y_true: Ground truth masks\n",
        "        y_pred: Predicted masks\n",
        "        smooth: Smoothing factor to avoid division by zero\n",
        "\n",
        "    Returns:\n",
        "        Recall (0-1)\n",
        "    \"\"\"\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    true_positives = K.sum(y_true_f * y_pred_f)\n",
        "    actual_positives = K.sum(y_true_f)\n",
        "\n",
        "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
        "    return recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cL84pFf2uom"
      },
      "outputs": [],
      "source": [
        "# CELL 4: Define ResUNet model architecture\n",
        "def conv_block(inputs, filters, kernel_size=3, strides=1, padding='same'):\n",
        "    \"\"\"Convolutional block with batch normalization and activation\"\"\"\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(inputs, filters, kernel_size=3, strides=1):\n",
        "    \"\"\"Residual block with skip connection\"\"\"\n",
        "    x = conv_block(inputs, filters, kernel_size, strides)\n",
        "    x = conv_block(x, filters, kernel_size, 1)\n",
        "\n",
        "    # If the input and output dimensions differ, use 1x1 conv to match dimensions\n",
        "    if strides > 1 or inputs.shape[-1] != filters:\n",
        "        shortcut = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "    else:\n",
        "        shortcut = inputs\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def build_resunet_model(input_shape=(256, 256, 3), num_classes=1):\n",
        "    \"\"\"Build ResUNet model\n",
        "\n",
        "    Args:\n",
        "        input_shape: Input image shape (height, width, channels)\n",
        "        num_classes: Number of output classes (1 for binary segmentation)\n",
        "\n",
        "    Returns:\n",
        "        Compiled ResUNet model\n",
        "    \"\"\"\n",
        "    # Input layer\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Initial Convolution\n",
        "    x = conv_block(inputs, 64, kernel_size=7, strides=1)\n",
        "\n",
        "    # Encoder blocks with residual connections and max pooling\n",
        "    # Encoder block 1\n",
        "    skip1 = residual_block(x, 64)\n",
        "    x = layers.MaxPooling2D(2)(skip1)\n",
        "\n",
        "    # Encoder block 2\n",
        "    skip2 = residual_block(x, 128)\n",
        "    x = layers.MaxPooling2D(2)(skip2)\n",
        "\n",
        "    # Encoder block 3\n",
        "    skip3 = residual_block(x, 256)\n",
        "    x = layers.MaxPooling2D(2)(skip3)\n",
        "\n",
        "    # Bridge\n",
        "    x = residual_block(x, 512)\n",
        "\n",
        "    # Decoder blocks with upsampling and concatenation with skip connections\n",
        "    # Decoder block 1\n",
        "    x = layers.UpSampling2D(2)(x)\n",
        "    x = conv_block(x, 256)\n",
        "    x = layers.Concatenate()([x, skip3])\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    # Decoder block 2\n",
        "    x = layers.UpSampling2D(2)(x)\n",
        "    x = conv_block(x, 128)\n",
        "    x = layers.Concatenate()([x, skip2])\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    # Decoder block 3\n",
        "    x = layers.UpSampling2D(2)(x)\n",
        "    x = conv_block(x, 64)\n",
        "    x = layers.Concatenate()([x, skip1])\n",
        "    x = residual_block(x, 64)\n",
        "\n",
        "    # Output layer\n",
        "    if num_classes > 1:\n",
        "        # Multi-class segmentation\n",
        "        outputs = layers.Conv2D(num_classes, kernel_size=1, activation='softmax')(x)\n",
        "    else:\n",
        "        # Binary segmentation\n",
        "        outputs = layers.Conv2D(num_classes, kernel_size=1, activation='sigmoid')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n05G0jq52urH",
        "outputId": "5f67a4b4-cf36-47b0-fc4d-2d3af93111e3"
      },
      "outputs": [],
      "source": [
        "# CELL 5: Load and visualize data\n",
        "# Set paths\n",
        "base_path = \"/content/drive/MyDrive/ResUNet_preprocessed\"  # Update this to your actual path\n",
        "\n",
        "# Create datasets\n",
        "batch_size = 8\n",
        "train_dataset = create_dataset(base_path, 'train', batch_size=batch_size)\n",
        "val_dataset = create_dataset(base_path, 'val', batch_size=batch_size)\n",
        "test_dataset = create_dataset(base_path, 'test', batch_size=batch_size)\n",
        "\n",
        "# Visualize some samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NRADQD9U2uta",
        "outputId": "3790d75b-808d-43e9-872f-ffabf84ee7e8"
      },
      "outputs": [],
      "source": [
        "# CELL 6: Build and compile model (updated)\n",
        "# Build model\n",
        "input_shape = (256, 256, 3)  # Based on your preprocessing\n",
        "model = build_resunet_model(input_shape)\n",
        "\n",
        "# Compile model with all the important metrics\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "    loss=bce_dice_loss,\n",
        "    metrics=[\n",
        "        dice_coefficient,\n",
        "        iou_score,\n",
        "        'binary_accuracy',\n",
        "        f1_score_metric,\n",
        "        precision_metric,\n",
        "        recall_metric\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIWoRe5o3JCL"
      },
      "outputs": [],
      "source": [
        "# CELL 7: Define callbacks (updated)\n",
        "# Create model checkpoint callback\n",
        "checkpoint_path = \"/content/drive/MyDrive/flood_resunet_weights/model.h5\"\n",
        "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "\n",
        "# Define callbacks with enhanced logging\n",
        "callbacks_list = [\n",
        "    callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_path,\n",
        "        monitor='val_dice_coefficient',\n",
        "        save_best_only=True,\n",
        "        mode='max'\n",
        "    ),\n",
        "    callbacks.EarlyStopping(\n",
        "        monitor='val_dice_coefficient',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        mode='max'\n",
        "    ),\n",
        "    callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_dice_coefficient',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        mode='max'\n",
        "    ),\n",
        "    callbacks.TensorBoard(\n",
        "        log_dir='/content/drive/MyDrive/flood_resunet_logs',\n",
        "        histogram_freq=1,\n",
        "        update_freq='epoch',\n",
        "        write_graph=True,\n",
        "        write_images=True,\n",
        "        profile_batch=0\n",
        "    ),\n",
        "    # Add CSV logger to save all metrics\n",
        "    callbacks.CSVLogger(\n",
        "        '/content/drive/MyDrive/flood_resunet_training_log.csv',\n",
        "        separator=',',\n",
        "        append=False\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRAvAKQx3JEc",
        "outputId": "8bf44171-cdc7-4095-8736-285795d1400c"
      },
      "outputs": [],
      "source": [
        "# CELL 8: Train model\n",
        "# Calculate steps per epoch\n",
        "steps_per_epoch = len(glob.glob(os.path.join(base_path, 'train', 'images', '*.npy'))) // batch_size\n",
        "validation_steps = len(glob.glob(os.path.join(base_path, 'val', 'images', '*.npy'))) // batch_size\n",
        "callbacks_list = [\n",
        "    callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_path,\n",
        "        monitor='val_dice_coefficient',\n",
        "        save_best_only=True,\n",
        "        mode='max'\n",
        "    ),\n",
        "    callbacks.EarlyStopping(\n",
        "        monitor='val_dice_coefficient',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        mode='max'  # Added mode parameter\n",
        "    ),\n",
        "    callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_dice_coefficient',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        mode='max'  # Make sure this is consistent too\n",
        "    ),\n",
        "    callbacks.TensorBoard(\n",
        "        log_dir='/content/drive/MyDrive/flood_resunet_logs1',\n",
        "        histogram_freq=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train model\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks_list\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MQmyhYrL3JGs",
        "outputId": "c6918031-9854-41e8-e8e3-a06e5d549808"
      },
      "outputs": [],
      "source": [
        "# CELL 9: Plot training history (updated)\n",
        "def plot_history(history):\n",
        "    \"\"\"\n",
        "    Plot comprehensive training history with all metrics\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(3, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Plot Dice coefficient\n",
        "    plt.subplot(3, 2, 2)\n",
        "    plt.plot(history.history['dice_coefficient'], label='Training Dice')\n",
        "    plt.plot(history.history['val_dice_coefficient'], label='Validation Dice')\n",
        "    plt.title('Dice Coefficient')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Dice')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Plot IoU\n",
        "    plt.subplot(3, 2, 3)\n",
        "    plt.plot(history.history['iou_score'], label='Training IoU')\n",
        "    plt.plot(history.history['val_iou_score'], label='Validation IoU')\n",
        "    plt.title('IoU Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Plot binary accuracy\n",
        "    plt.subplot(3, 2, 4)\n",
        "    plt.plot(history.history['binary_accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_binary_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Binary Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Plot F1 Score\n",
        "    plt.subplot(3, 2, 5)\n",
        "    plt.plot(history.history['f1_score_metric'], label='Training F1')\n",
        "    plt.plot(history.history['val_f1_score_metric'], label='Validation F1')\n",
        "    plt.title('F1 Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Plot Precision and Recall\n",
        "    plt.subplot(3, 2, 6)\n",
        "    plt.plot(history.history['precision_metric'], label='Training Precision')\n",
        "    plt.plot(history.history['val_precision_metric'], label='Validation Precision')\n",
        "    plt.plot(history.history['recall_metric'], label='Training Recall')\n",
        "    plt.plot(history.history['val_recall_metric'], label='Validation Recall')\n",
        "    plt.title('Precision and Recall')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Score')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/flood_resunet_training_history.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08EmcoKH3JI4",
        "outputId": "2c5aae19-83e4-4ba8-cf52-ace41f9ebdae"
      },
      "outputs": [],
      "source": [
        "# CELL 10: Evaluate model on test set (updated)\n",
        "# Load best model with all custom metrics\n",
        "best_model = models.load_model(checkpoint_path, custom_objects={\n",
        "    'dice_coefficient': dice_coefficient,\n",
        "    'dice_loss': dice_loss,\n",
        "    'bce_dice_loss': bce_dice_loss,\n",
        "    'iou_score': iou_score,\n",
        "    'f1_score_metric': f1_score_metric,\n",
        "    'precision_metric': precision_metric,\n",
        "    'recall_metric': recall_metric\n",
        "})\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results = best_model.evaluate(test_dataset)\n",
        "print(\"\\nTest Results:\")\n",
        "for metric_name, value in zip(best_model.metrics_names, test_results):\n",
        "    print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "# Save test results to file\n",
        "import json\n",
        "test_metrics = {metric_name: float(value) for metric_name, value in zip(best_model.metrics_names, test_results)}\n",
        "with open('/content/drive/MyDrive/flood_resunet_test_metrics.json', 'w') as f:\n",
        "    json.dump(test_metrics, f, indent=4)\n",
        "print(\"Test metrics saved to JSON file\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MLmqlvRC3RpO",
        "outputId": "0c019878-2c65-485d-ce23-9ce5f743ffb8"
      },
      "outputs": [],
      "source": [
        "# CELL 11: Visualize predictions\n",
        "def visualize_predictions(model, dataset, num_samples=5):\n",
        "    \"\"\"Visualize model predictions against ground truth\"\"\"\n",
        "    plt.figure(figsize=(15, 5*num_samples))\n",
        "\n",
        "    # Get samples from dataset\n",
        "    for i, (images, masks) in enumerate(dataset.take(num_samples)):\n",
        "        if i >= num_samples:\n",
        "            break\n",
        "\n",
        "        # Get predictions\n",
        "        preds = model.predict(images)\n",
        "\n",
        "        for j in range(min(images.shape[0], 3)):\n",
        "            # Get image, mask, and prediction\n",
        "            image = images[j].numpy()\n",
        "            mask = masks[j].numpy()\n",
        "            pred = preds[j]\n",
        "\n",
        "            # Normalize image for visualization (0-1 range)\n",
        "            image_viz = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
        "\n",
        "            # Composite RGB using VH and VV channels\n",
        "            rgb_viz = np.stack([\n",
        "                image_viz[:, :, 0],  # VH as R\n",
        "                image_viz[:, :, 1],  # VV as G\n",
        "                (image_viz[:, :, 0] + image_viz[:, :, 1]) / 2  # Average as B\n",
        "            ], axis=-1)\n",
        "\n",
        "            # Clip to 0-1 range\n",
        "            rgb_viz = np.clip(rgb_viz, 0, 1)\n",
        "\n",
        "            # Convert masks to binary\n",
        "            mask_binary = (mask > 0.5).astype(np.float32)\n",
        "            pred_binary = (pred > 0.5).astype(np.float32)\n",
        "\n",
        "            # Calculate metrics for this sample\n",
        "            dice = np.sum(2 * mask_binary * pred_binary) / (np.sum(mask_binary) + np.sum(pred_binary) + 1e-8)\n",
        "\n",
        "            # Plot original image\n",
        "            row_idx = i * 3 + j\n",
        "            plt.subplot(num_samples * 3, 3, row_idx * 3 + 1)\n",
        "            plt.imshow(rgb_viz)\n",
        "            plt.title(f\"SAR Image - Sample {row_idx+1}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Plot ground truth mask\n",
        "            plt.subplot(num_samples * 3, 3, row_idx * 3 + 2)\n",
        "            plt.imshow(mask.squeeze(), cmap='Blues')\n",
        "            plt.title(f\"Ground Truth\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Plot prediction\n",
        "            plt.subplot(num_samples * 3, 3, row_idx * 3 + 3)\n",
        "            plt.imshow(pred.squeeze(), cmap='Blues')\n",
        "            plt.title(f\"Prediction (Dice={dice:.3f})\")\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/flood_resunet_predictions.png')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize predictions on test set\n",
        "visualize_predictions(best_model, test_dataset, num_samples=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7lgBDgX3Rv6",
        "outputId": "56aebbb8-91ec-4f99-b182-848b8d3343fa"
      },
      "outputs": [],
      "source": [
        "# CELL 12: Calculate and report detailed metrics (updated)\n",
        "def calculate_metrics(model, dataset, threshold=0.5):\n",
        "    \"\"\"Calculate comprehensive metrics on dataset with pixel-level and image-level evaluation\"\"\"\n",
        "    y_true_all = []\n",
        "    y_pred_all = []\n",
        "    dice_scores = []\n",
        "    iou_scores = []\n",
        "\n",
        "    # For per-image metrics\n",
        "    image_metrics = []\n",
        "\n",
        "    for images, masks in dataset:\n",
        "        # Get predictions\n",
        "        preds = model.predict(images)\n",
        "\n",
        "        # Process each image in the batch\n",
        "        for i in range(len(images)):\n",
        "            mask = masks[i].numpy()\n",
        "            pred = preds[i]\n",
        "\n",
        "            # Calculate per-image metrics\n",
        "            mask_flat = mask.flatten()\n",
        "            pred_flat = pred.flatten()\n",
        "\n",
        "            # Apply threshold\n",
        "            pred_binary = (pred_flat > threshold).astype(np.int32)\n",
        "            mask_binary = (mask_flat > threshold).astype(np.int32)\n",
        "\n",
        "            # Add to overall lists\n",
        "            y_true_all.extend(mask_binary)\n",
        "            y_pred_all.extend(pred_binary)\n",
        "\n",
        "            # Calculate per-image Dice\n",
        "            intersection = np.sum(mask_binary * pred_binary)\n",
        "            dice = (2. * intersection) / (np.sum(mask_binary) + np.sum(pred_binary) + 1e-8)\n",
        "            dice_scores.append(dice)\n",
        "\n",
        "            # Calculate per-image IoU\n",
        "            union = np.sum(mask_binary) + np.sum(pred_binary) - intersection\n",
        "            iou = intersection / (union + 1e-8)\n",
        "            iou_scores.append(iou)\n",
        "\n",
        "            # Per-image confusion matrix\n",
        "            img_tn, img_fp, img_fn, img_tp = confusion_matrix(mask_binary, pred_binary, labels=[0, 1]).ravel()\n",
        "\n",
        "            # Per-image metrics\n",
        "            img_precision = img_tp / (img_tp + img_fp + 1e-8)\n",
        "            img_recall = img_tp / (img_tp + img_fn + 1e-8)\n",
        "            img_f1 = 2 * (img_precision * img_recall) / (img_precision + img_recall + 1e-8)\n",
        "            img_accuracy = (img_tp + img_tn) / (img_tp + img_tn + img_fp + img_fn)\n",
        "\n",
        "            # Store per-image metrics\n",
        "            image_metrics.append({\n",
        "                'dice': dice,\n",
        "                'iou': iou,\n",
        "                'precision': img_precision,\n",
        "                'recall': img_recall,\n",
        "                'f1': img_f1,\n",
        "                'accuracy': img_accuracy,\n",
        "                'tp': int(img_tp),\n",
        "                'fp': int(img_fp),\n",
        "                'tn': int(img_tn),\n",
        "                'fn': int(img_fn)\n",
        "            })\n",
        "\n",
        "    # Calculate overall metrics from all pixels\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all, labels=[0, 1]).ravel()\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    precision = tp / (tp + fp + 1e-8)\n",
        "    recall = tp / (tp + fn + 1e-8)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    specificity = tn / (tn + fp + 1e-8)\n",
        "\n",
        "    # Calculate IoU\n",
        "    intersection = tp\n",
        "    union = tp + fp + fn\n",
        "    iou = intersection / (union + 1e-8)\n",
        "\n",
        "    # Calculate mean Dice and IoU across all images\n",
        "    mean_dice = np.mean(dice_scores)\n",
        "    mean_iou = np.mean(iou_scores)\n",
        "\n",
        "    print(\"\\n======== Detailed Metrics ========\")\n",
        "    print(f\"Overall Metrics (pixel-level):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall/Sensitivity: {recall:.4f}\")\n",
        "    print(f\"Specificity: {specificity:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"IoU: {iou:.4f}\")\n",
        "    print(f\"Dice Coefficient: {(2 * tp) / (2 * tp + fp + fn + 1e-8):.4f}\")\n",
        "\n",
        "    print(\"\\nMean Per-Image Metrics:\")\n",
        "    print(f\"Mean Dice: {mean_dice:.4f}\")\n",
        "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(f\"True Positives: {tp}\")\n",
        "    print(f\"False Positives: {fp}\")\n",
        "    print(f\"True Negatives: {tn}\")\n",
        "    print(f\"False Negatives: {fn}\")\n",
        "\n",
        "    # Calculate per-class metrics (for binary segmentation)\n",
        "    print(\"\\nPer-Class Metrics:\")\n",
        "    # Background (class 0)\n",
        "    bg_precision = tn / (tn + fn + 1e-8)\n",
        "    bg_recall = tn / (tn + fp + 1e-8)\n",
        "    bg_f1 = 2 * (bg_precision * bg_recall) / (bg_precision + bg_recall + 1e-8)\n",
        "    print(f\"Background - Precision: {bg_precision:.4f}, Recall: {bg_recall:.4f}, F1: {bg_f1:.4f}\")\n",
        "\n",
        "    # Flood (class 1)\n",
        "    flood_precision = precision\n",
        "    flood_recall = recall\n",
        "    flood_f1 = f1\n",
        "    print(f\"Flood - Precision: {flood_precision:.4f}, Recall: {flood_recall:.4f}, F1: {flood_f1:.4f}\")\n",
        "\n",
        "    # Save per-image metrics to CSV\n",
        "    import pandas as pd\n",
        "    img_metrics_df = pd.DataFrame(image_metrics)\n",
        "    img_metrics_df.to_csv('/content/drive/MyDrive/flood_resunet_per_image_metrics.csv', index_label='image_id')\n",
        "    print(\"\\nPer-image metrics saved to CSV file\")\n",
        "\n",
        "    # Return comprehensive metrics as dictionary\n",
        "    return {\n",
        "        'overall': {\n",
        "            'accuracy': float(accuracy),\n",
        "            'precision': float(precision),\n",
        "            'recall': float(recall),\n",
        "            'specificity': float(specificity),\n",
        "            'f1': float(f1),\n",
        "            'iou': float(iou),\n",
        "            'dice': float((2 * tp) / (2 * tp + fp + fn + 1e-8))\n",
        "        },\n",
        "        'per_image_mean': {\n",
        "            'dice': float(mean_dice),\n",
        "            'iou': float(mean_iou)\n",
        "        },\n",
        "        'confusion_matrix': {\n",
        "            'tn': int(tn),\n",
        "            'fp': int(fp),\n",
        "            'fn': int(fn),\n",
        "            'tp': int(tp)\n",
        "        },\n",
        "        'per_class': {\n",
        "            'background': {\n",
        "                'precision': float(bg_precision),\n",
        "                'recall': float(bg_recall),\n",
        "                'f1': float(bg_f1)\n",
        "            },\n",
        "            'flood': {\n",
        "                'precision': float(flood_precision),\n",
        "                'recall': float(flood_recall),\n",
        "                'f1': float(flood_f1)\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Calculate comprehensive metrics on test set\n",
        "detailed_metrics = calculate_metrics(best_model, test_dataset)\n",
        "\n",
        "# Save detailed metrics to file\n",
        "with open('/content/drive/MyDrive/flood_resunet_detailed_metrics.json', 'w') as f:\n",
        "    json.dump(detailed_metrics, f, indent=4)\n",
        "\n",
        "print(\"Detailed metrics saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "qt0zKCw63Wrd",
        "outputId": "6ba385c5-1cdb-4192-f0d1-ccf8ef0dd479"
      },
      "outputs": [],
      "source": [
        "# CELL 13: Save model and metrics\n",
        "# Save model in TensorFlow SavedModel format (recommended)\n",
        "best_model.save('/content/drive/MyDrive/flood_resunet_model')\n",
        "\n",
        "# Save metrics to file\n",
        "import json\n",
        "with open('/content/drive/MyDrive/flood_resunet_metrics.json', 'w') as f:\n",
        "    # Convert confusion matrix values to int for JSON serialization\n",
        "    metrics['confusion_matrix'] = {k: int(v) for k, v in metrics['confusion_matrix'].items()}\n",
        "    json.dump(metrics, f, indent=4)\n",
        "\n",
        "print(\"Model and metrics saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3F4Ruv-r3Wtp",
        "outputId": "7a5fb9bd-28a9-4f6c-f9e9-079c262439a5"
      },
      "outputs": [],
      "source": [
        "# CELL 14: Create example inference function for new images\n",
        "def predict_flood(model, image_path, output_path=None):\n",
        "    \"\"\"Predict flood on a new SAR image\n",
        "\n",
        "    Args:\n",
        "        model: Loaded ResUNet model\n",
        "        image_path: Path to input .npy file (preprocessed)\n",
        "        output_path: Path to save visualization (optional)\n",
        "\n",
        "    Returns:\n",
        "        Predicted flood mask\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    image = np.load(image_path)\n",
        "\n",
        "    # Add batch dimension\n",
        "    image_batch = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(image_batch)[0]\n",
        "\n",
        "    # Squeeze prediction\n",
        "    prediction = prediction.squeeze()\n",
        "\n",
        "    # Create binary mask\n",
        "    binary_mask = (prediction > 0.5).astype(np.uint8)\n",
        "\n",
        "    if output_path:\n",
        "        # Visualize\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Normalize image for visualization\n",
        "        image_viz = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
        "\n",
        "        # Create composite RGB\n",
        "        rgb_viz = np.stack([\n",
        "            image_viz[:, :, 0],  # VH as R\n",
        "            image_viz[:, :, 1],  # VV as G\n",
        "            (image_viz[:, :, 0] + image_viz[:, :, 1]) / 2  # Average as B\n",
        "        ], axis=-1)\n",
        "\n",
        "        # Plot original image\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(rgb_viz)\n",
        "        plt.title(\"SAR Image\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot probability map\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(prediction, cmap='Blues')\n",
        "        plt.colorbar(fraction=0.046, pad=0.04)\n",
        "        plt.title(\"Flood Probability\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot binary mask\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(binary_mask, cmap='Blues')\n",
        "        plt.title(\"Flood Mask (Binary)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_path)\n",
        "        plt.close()\n",
        "\n",
        "    return binary_mask\n",
        "\n",
        "# Example usage (uncomment when needed)\n",
        "\"\"\"\n",
        "test_image_path = \"/content/drive/MyDrive/ResUNet_preprocessed/test/images/test_0001.npy\"\n",
        "output_path = \"/content/drive/MyDrive/test_prediction.png\"\n",
        "flood_mask = predict_flood(best_model, test_image_path, output_path)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkRI4D5yF_Na"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
